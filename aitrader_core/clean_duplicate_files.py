#!/usr/bin/env python3
"""
æ¸…ç†é‡å¤å’Œå¼‚å¸¸çš„è‚¡ç¥¨æ•°æ®æ–‡ä»¶
"""
import os
from pathlib import Path
from collections import defaultdict

def clean_duplicate_files():
    """æ¸…ç†é‡å¤å’Œå¼‚å¸¸çš„è‚¡ç¥¨æ•°æ®æ–‡ä»¶"""
    data_dir = Path.home() / "stock_data"
    
    if not data_dir.exists():
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return
    
    # ç»Ÿè®¡æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = list(data_dir.glob("*.csv"))
    print(f"ğŸ“‚ å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ (æå–å‰6ä½æ•°å­—)
    stock_groups = defaultdict(list)
    
    for csv_file in csv_files:
        filename = csv_file.name
        # æå–è‚¡ç¥¨ä»£ç  (å‰6ä½æ•°å­—)
        stock_code = ''.join(filter(str.isdigit, filename.split('_')[0]))[:6]
        if stock_code:
            stock_groups[stock_code].append(csv_file)
    
    # æ‰¾å‡ºé‡å¤æ–‡ä»¶
    duplicate_count = 0
    deleted_count = 0
    
    for stock_code, files in stock_groups.items():
        if len(files) > 1:
            duplicate_count += 1
            print(f"\nğŸ” è‚¡ç¥¨ä»£ç  {stock_code} æœ‰ {len(files)} ä¸ªæ–‡ä»¶:")
            
            # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åº,ä¿ç•™æœ€æ–°çš„
            files_sorted = sorted(files, key=lambda f: f.stat().st_mtime, reverse=True)
            
            # æ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
            for i, f in enumerate(files_sorted):
                size_kb = f.stat().st_size / 1024
                mtime = f.stat().st_mtime
                status = "âœ… ä¿ç•™ (æœ€æ–°)" if i == 0 else "ğŸ—‘ï¸ åˆ é™¤"
                print(f"  {status}: {f.name} ({size_kb:.1f} KB)")
            
            # åˆ é™¤æ—§æ–‡ä»¶
            for f in files_sorted[1:]:
                try:
                    f.unlink()
                    deleted_count += 1
                    print(f"     å·²åˆ é™¤: {f.name}")
                except Exception as e:
                    print(f"     âš ï¸ åˆ é™¤å¤±è´¥: {e}")
    
    print(f"\n" + "="*60)
    print(f"âœ… æ¸…ç†å®Œæˆ!")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   - æ€»æ–‡ä»¶æ•°: {len(csv_files)}")
    print(f"   - é‡å¤è‚¡ç¥¨æ•°: {duplicate_count}")
    print(f"   - å·²åˆ é™¤æ–‡ä»¶: {deleted_count}")
    print(f"   - å‰©ä½™æ–‡ä»¶æ•°: {len(csv_files) - deleted_count}")
    print("="*60)

if __name__ == "__main__":
    clean_duplicate_files()

