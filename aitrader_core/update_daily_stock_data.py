#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥è‚¡ç¥¨æ•°æ®å¢é‡æ›´æ–°è„šæœ¬
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨è·å–æœ€æ–°äº¤æ˜“æ—¥
2. å¢é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°æ•°æ®ï¼ˆAè‚¡å…¨é‡ï¼‰
3. æ”¯æŒä¼ä¸šå¾®ä¿¡æ¨é€é€šçŸ¥

æ•°æ®æ¥æºï¼šbaostock
é€‚ç”¨äºï¼šaitrader_v3.3é¡¹ç›®
"""

import baostock as bs
import pandas as pd
import os
import sys
import io
import time
import requests
import json
from datetime import datetime, timedelta
import logging
import re

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# é…ç½®æ—¥å¿—
log_dir = os.path.join(PROJECT_ROOT, 'logs')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'daily_update.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é…ç½®å‚æ•°
# ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ç›®å½•çš„stock_dataï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é¡¹ç›®ç›®å½•
USER_STOCK_DATA_DIR = os.path.expanduser("~/stock_data")
PROJECT_STOCK_DATA_DIR = os.path.join(PROJECT_ROOT, "data", "quotes")

if os.path.exists(USER_STOCK_DATA_DIR):
    STOCK_DATA_DIR = USER_STOCK_DATA_DIR
    logger.info(f"ä½¿ç”¨ç”¨æˆ·ç›®å½•æ•°æ®: {STOCK_DATA_DIR}")
else:
    STOCK_DATA_DIR = PROJECT_STOCK_DATA_DIR
    logger.info(f"ä½¿ç”¨é¡¹ç›®ç›®å½•æ•°æ®: {STOCK_DATA_DIR}")
ADJUST_FLAG = "2"  # å‰å¤æƒ
WEBHOOK_URL = ""  # ä¼ä¸šå¾®ä¿¡Webhookåœ°å€ï¼ˆå¯é€‰ï¼‰

def login_baostock():
    """ç™»å½•baostock"""
    lg = bs.login()
    if lg.error_code != '0':
        logger.error(f"ç™»å½•å¤±è´¥: {lg.error_msg}")
        sys.exit(1)
    else:
        logger.info("ç™»å½•baostockæˆåŠŸ")
        return lg

def logout_baostock():
    """ç™»å‡ºbaostock"""
    bs.logout()
    logger.info("ç™»å‡ºbaostockæˆåŠŸ")

def get_latest_trading_date():
    """è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
    today = datetime.now()
    for i in range(7):  # å¾€å‰æ¨7å¤©ï¼Œæ‰¾åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥
        check_date = today - timedelta(days=i)
        if check_date.weekday() < 5:  # 0-4 for Monday-Friday
            return check_date.strftime('%Y-%m-%d')
    return None

def send_wecom_notification(message):
    """å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥"""
    if not WEBHOOK_URL:
        return False
        
    data = {
        "msgtype": "text",
        "text": {
            "content": message
        }
    }
    
    try:
        response = requests.post(WEBHOOK_URL, json=data, timeout=10)
        logger.info(f"ä¼ä¸šå¾®ä¿¡é€šçŸ¥ç»“æœ: {response.status_code}")
        return response.status_code == 200
    except Exception as e:
        logger.error(f"ä¼ä¸šå¾®ä¿¡é€šçŸ¥å¤±è´¥: {e}")
        return False

def update_stock_data_incremental(lg, stock_code_full, stock_name, latest_trading_date):
    """å¢é‡æ›´æ–°å•åªè‚¡ç¥¨æ•°æ®"""
    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    file_name_sanitized = re.sub(r'[\\/:*?\"<>|]', '', stock_name)
    file_path = os.path.join(STOCK_DATA_DIR, f"{stock_code_full.split('.')[-1]}_{file_name_sanitized}.csv")

    if not os.path.exists(file_path):
        logger.warning(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°ã€‚")
        return 0

    try:
        # è¯»å–ç°æœ‰æ•°æ®
        existing_df = pd.read_csv(file_path)
        if 'date' not in existing_df.columns:
            logger.warning(f"æ–‡ä»¶ {file_path} ç¼ºå°‘ 'date' åˆ—ï¼Œè·³è¿‡æ›´æ–°ã€‚")
            return 0

        existing_df['date'] = pd.to_datetime(existing_df['date'])
        last_local_date = existing_df['date'].max().strftime('%Y-%m-%d')

        # å¦‚æœæœ¬åœ°æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡
        if last_local_date >= latest_trading_date:
            return 0

        # æŸ¥è¯¢èµ·å§‹æ—¥æœŸä¸ºæœ¬åœ°æœ€åæ—¥æœŸçš„ä¸‹ä¸€å¤©
        start_date_to_query = (datetime.strptime(last_local_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
        
        # æŸ¥è¯¢æ–°æ•°æ®
        rs = bs.query_history_k_data_plus(
            stock_code_full,
            "date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,isST",
            start_date=start_date_to_query,
            end_date=latest_trading_date,
            frequency="d",
            adjustflag=ADJUST_FLAG
        )

        data_list = []
        while (rs.error_code == '0') & rs.next():
            data_list.append(rs.get_row_data())

        if data_list:
            new_df = pd.DataFrame(data_list, columns=rs.fields)
            new_df['date'] = pd.to_datetime(new_df['date'])
            
            # åˆå¹¶å¹¶å»é‡
            updated_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=['date']).sort_values(by='date')
            updated_df.to_csv(file_path, index=False)
            
            logger.info(f"{stock_code_full} {stock_name} æ–°å¢ {len(new_df)} æ¡è®°å½•")
            return len(new_df)
        else:
            return 0
            
    except Exception as e:
        logger.error(f"æ›´æ–°è‚¡ç¥¨ {stock_code_full} å¤±è´¥: {e}")
        return 0

def main():
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥è‚¡ç¥¨æ•°æ®å¢é‡æ›´æ–°ä»»åŠ¡")
    logger.info("=" * 60)
    
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    if not os.path.exists(STOCK_DATA_DIR):
        logger.error(f"è‚¡ç¥¨æ•°æ®ç›®å½• {STOCK_DATA_DIR} ä¸å­˜åœ¨ï¼")
        send_wecom_notification(f"âŒ è‚¡ç¥¨æ•°æ®æ›´æ–°å¤±è´¥ï¼šæ•°æ®ç›®å½•ä¸å­˜åœ¨\næ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        return

    lg = login_baostock()
    latest_trading_date = get_latest_trading_date()
    
    if not latest_trading_date:
        logger.error("æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œé€€å‡ºæ•°æ®æ›´æ–°ã€‚")
        logout_baostock()
        send_wecom_notification(f"âŒ è‚¡ç¥¨æ•°æ®æ›´æ–°å¤±è´¥ï¼šæ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥\næ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        return

    logger.info(f"æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_date}")
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    stock_files = [f for f in os.listdir(STOCK_DATA_DIR) if f.endswith('.csv')]
    total_files = len(stock_files)
    updated_count = 0
    processed_count = 0
    error_count = 0
    
    logger.info(f"å¼€å§‹å¤„ç† {total_files} ä¸ªè‚¡ç¥¨æ–‡ä»¶")
    
    for file_name in stock_files:
        processed_count += 1
        try:
            # ä»æ–‡ä»¶åè§£æè‚¡ç¥¨ä»£ç 
            stock_id = file_name.split('_')[0]
            
            # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¸‚åœº
            if stock_id.startswith('6'):
                stock_code_full = f'sh.{stock_id}'
            elif stock_id.startswith(('0', '3')):
                stock_code_full = f'sz.{stock_id}'
            elif stock_id.startswith(('8', '4')):  # åŒ—äº¤æ‰€
                stock_code_full = f'bj.{stock_id}'
            else:
                logger.warning(f"æœªçŸ¥å¸‚åœºä»£ç : {stock_id}")
                continue

            stock_name = file_name.split('_', 1)[1].replace('.csv', '') if '_' in file_name else stock_id
            
            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯50åªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
            if processed_count % 50 == 0:
                progress = processed_count / total_files * 100
                elapsed = time.time() - start_time
                eta = (elapsed / processed_count) * (total_files - processed_count)
                logger.info(f"[{progress:.1f}%] è¿›åº¦: {processed_count}/{total_files}, å·²æ›´æ–°: {updated_count}, é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")
            
            # æ›´æ–°æ•°æ®
            added_rows = update_stock_data_incremental(lg, stock_code_full, stock_name, latest_trading_date)
            if added_rows > 0:
                updated_count += 1
            
            # æ¯æ›´æ–°200åªè‚¡ç¥¨ä¼‘æ¯ä¸€ä¸‹
            if processed_count % 200 == 0:
                time.sleep(1)
                
        except Exception as e:
            error_count += 1
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    end_time = time.time()
    duration = end_time - start_time
    
    logger.info("-" * 60)
    logger.info("æ¯æ—¥æ•°æ®æ›´æ–°å®Œæˆ!")
    logger.info(f"æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_date}")
    logger.info(f"æ€»æ–‡ä»¶æ•°: {total_files}")
    logger.info(f"æˆåŠŸæ£€æŸ¥: {processed_count}")
    logger.info(f"å®é™…æ›´æ–°: {updated_count}")
    logger.info(f"é”™è¯¯æ•°é‡: {error_count}")
    logger.info(f"æ€»è€—æ—¶: {duration:.2f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
    logger.info("=" * 60)
    
    logout_baostock()
    
    # å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥
    if updated_count > 0 or error_count > 0:
        status_icon = "âœ…" if error_count == 0 else "âš ï¸"
        message = f"""{status_icon} è‚¡ç¥¨æ•°æ®æ›´æ–°å®Œæˆ

ğŸ“… æ›´æ–°æ—¥æœŸ: {latest_trading_date}
ğŸ“Š æ€»è‚¡ç¥¨æ•°: {total_files}
ğŸ”„ å®é™…æ›´æ–°: {updated_count}
âŒ é”™è¯¯æ•°é‡: {error_count}
â±ï¸ è€—æ—¶: {duration:.1f}ç§’

æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"""
        
        send_wecom_notification(message)
    else:
        logger.info("æ— æ–°æ•°æ®éœ€è¦æ›´æ–°ï¼Œè·³è¿‡é€šçŸ¥")

if __name__ == '__main__':
    main()

