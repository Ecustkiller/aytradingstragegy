#!/usr/bin/env python3
"""
Aè‚¡å…¨é‡æ•°æ®æ›´æ–°è„šæœ¬ - Tushare Directç‰ˆæœ¬ï¼ˆé€‚ç”¨äºStreamlit Cloudï¼‰
ç›´æ¥è°ƒç”¨Tushare APIï¼Œæ— éœ€subprocessï¼Œé€‚åˆåœ¨Streamlitç•Œé¢ä¸­ç›´æ¥è°ƒç”¨
"""
import os
import sys
import pandas as pd
import tushare as ts
from pathlib import Path
from datetime import datetime, timedelta
import time

# Tushare Token
TUSHARE_TOKEN = os.environ.get('TUSHARE_TOKEN', 'ad56243b601d82fd5c4aaf04b72d4d9d567401898d46c20f4d905d59')

def get_stock_data_dir():
    """è·å–æ•°æ®ç›®å½•"""
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
    if 'STOCK_DATA_DIR' in os.environ:
        data_dir = Path(os.environ['STOCK_DATA_DIR'])
    # æœ¬åœ°ç¯å¢ƒ
    elif Path.home().exists():
        data_dir = Path.home() / "stock_data"
    # Streamlit Cloudç¯å¢ƒ
    else:
        project_root = Path(__file__).parent.parent
        data_dir = project_root / "data" / "stock_data"
    
    data_dir.mkdir(parents=True, exist_ok=True)
    return data_dir


def update_data_direct(progress_callback=None, log_callback=None):
    """
    ç›´æ¥æ›´æ–°æ•°æ®ï¼ˆé€‚ç”¨äºStreamlitç•Œé¢ç›´æ¥è°ƒç”¨ï¼‰
    
    Args:
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(progress, current, total, message)
        log_callback: æ—¥å¿—å›è°ƒå‡½æ•° callback(message)
    
    Returns:
        dict: æ›´æ–°ç»“æœç»Ÿè®¡
    """
    def log(msg):
        """æ—¥å¿—è¾“å‡º"""
        print(msg)
        sys.stdout.flush()
        if log_callback:
            log_callback(msg)
    
    def update_progress(progress, current, total, msg=""):
        """æ›´æ–°è¿›åº¦"""
        if progress_callback:
            progress_callback(progress, current, total, msg)
    
    try:
        # åˆå§‹åŒ–Tushare API
        log("âœ… æ­£åœ¨åˆå§‹åŒ–Tushare API...")
        pro = ts.pro_api(TUSHARE_TOKEN)
        
        # è·å–æ•°æ®ç›®å½•
        data_dir = get_stock_data_dir()
        log(f"âœ… æ•°æ®ç›®å½•: {data_dir}")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        log("ğŸ” æ­£åœ¨è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        stock_list = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name')
        total_stocks = len(stock_list)
        log(f"âœ… è·å–åˆ° {total_stocks} åªAè‚¡è‚¡ç¥¨")
        
        # ç¡®å®šæ—¶é—´èŒƒå›´
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
        log(f"ğŸ“… æ›´æ–°æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        
        # ç»Ÿè®¡å˜é‡
        success_count = 0
        skip_count = 0
        error_count = 0
        
        # éå†æ›´æ–°æ¯åªè‚¡ç¥¨
        for idx, row in stock_list.iterrows():
            ts_code = row['ts_code']
            name = row['name']
            
            # æ›´æ–°è¿›åº¦
            progress = int((idx + 1) / total_stocks * 100)
            update_progress(progress, idx + 1, total_stocks, f"æ­£åœ¨æ›´æ–°: {name}")
            
            csv_file = data_dir / f"{ts_code}_{name}.csv"
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            start_date_incremental = start_date
            if csv_file.exists():
                try:
                    existing_df = pd.read_csv(csv_file)
                    if not existing_df.empty and 'trade_date' in existing_df.columns:
                        last_date = str(existing_df['trade_date'].max())
                        # å¦‚æœå·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡
                        if last_date >= end_date:
                            skip_count += 1
                            if skip_count % 100 == 0:
                                log(f"â© å·²è·³è¿‡ {skip_count} åªæœ€æ–°è‚¡ç¥¨")
                            continue
                        start_date_incremental = last_date
                except Exception:
                    pass
            
            # ä¸‹è½½æ•°æ®
            try:
                df = pro.daily(
                    ts_code=ts_code,
                    start_date=start_date_incremental,
                    end_date=end_date,
                    adj='qfq'
                )
                
                if df is not None and not df.empty:
                    # åˆå¹¶æ•°æ®
                    if csv_file.exists():
                        existing_df = pd.read_csv(csv_file)
                        df = pd.concat([existing_df, df], ignore_index=True)
                        df = df.drop_duplicates(subset=['trade_date'], keep='last')
                        df = df.sort_values('trade_date')
                    
                    # ä¿å­˜
                    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
                    success_count += 1
                    
                    if success_count % 50 == 0:
                        log(f"âœ… å·²æ›´æ–° {success_count} åªè‚¡ç¥¨")
                else:
                    skip_count += 1
                
                # APIé™æµ (å…è´¹ç”¨æˆ·: 200æ¬¡/åˆ†é’Ÿ)
                time.sleep(0.32)
                
            except Exception as e:
                error_count += 1
                if error_count <= 5:
                    log(f"âŒ {name} æ›´æ–°å¤±è´¥: {str(e)[:50]}")
        
        # å®Œæˆ
        update_progress(100, total_stocks, total_stocks, "æ›´æ–°å®Œæˆ")
        log("=" * 60)
        log(f"âœ… æ›´æ–°å®Œæˆ")
        log(f"   æˆåŠŸ: {success_count} åª")
        log(f"   è·³è¿‡: {skip_count} åª")
        log(f"   å¤±è´¥: {error_count} åª")
        log("=" * 60)
        
        return {
            'success': success_count,
            'skip': skip_count,
            'error': error_count,
            'total': total_stocks
        }
        
    except Exception as e:
        log(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        import traceback
        log(traceback.format_exc())
        return None


if __name__ == "__main__":
    # å‘½ä»¤è¡Œæ¨¡å¼
    result = update_data_direct()
    if result:
        sys.exit(0)
    else:
        sys.exit(1)

