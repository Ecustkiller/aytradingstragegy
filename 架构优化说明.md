# ğŸ—ï¸ æ¶æ„ä¼˜åŒ–è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜é¡¹ç›®çš„æ¶æ„æ”¹è¿›å’Œæœ€ä½³å®è·µã€‚

---

## ğŸ“‹ å·²å®Œæˆçš„ä¼˜åŒ–

### 1. âœ… å®‰å…¨æ€§æ”¹è¿›

#### æ•æ„Ÿä¿¡æ¯ç®¡ç†
- **é—®é¢˜**ï¼šAPI Token ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
- **è§£å†³æ–¹æ¡ˆ**ï¼š
  - åˆ›å»º `.env.example` é…ç½®æ¨¡æ¿
  - ä½¿ç”¨ `python-dotenv` åŠ è½½ç¯å¢ƒå˜é‡
  - ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç çš„ Token
  - æ›´æ–° `.gitignore` é˜²æ­¢æ³„éœ²

#### å½±å“çš„æ–‡ä»¶
```
âœ“ aitrader_core/datafeed/tushare_loader.py
âœ“ aitrader_core/update_daily_stock_data.py
âœ“ aitrader_core/download_all_stock_data.py
âœ“ aitrader_core/update_with_tushare_direct.py
âœ“ README.md
âœ“ .gitignore
```

### 2. âœ… é…ç½®ç®¡ç†ç»Ÿä¸€

#### æ–°å¢æ¨¡å—ï¼š`modules/config_manager.py`

**åŠŸèƒ½**ï¼š
- é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®é¡¹
- æ”¯æŒç¯å¢ƒå˜é‡å’Œé»˜è®¤å€¼
- è‡ªåŠ¨åˆ›å»ºå¿…è¦ç›®å½•
- é…ç½®éªŒè¯å’Œæç¤º

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from modules.config_manager import Config

# è·å–é…ç½®
token = Config.get_tushare_token()
data_dir = Config.STOCK_DATA_DIR
log_level = Config.LOG_LEVEL

# æ‰“å°é…ç½®ä¿¡æ¯
Config.print_config()
```

**ä¼˜åŠ¿**ï¼š
- é…ç½®é›†ä¸­ç®¡ç†ï¼Œæ˜“äºç»´æŠ¤
- ç±»å‹å®‰å…¨ï¼Œé¿å…æ‹¼å†™é”™è¯¯
- è‡ªåŠ¨éªŒè¯ï¼ŒåŠæ—¶å‘ç°é—®é¢˜

### 3. âœ… é”™è¯¯å¤„ç†ç»Ÿä¸€

#### æ–°å¢æ¨¡å—ï¼š`modules/error_handler.py`

**åŠŸèƒ½**ï¼š
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†è£…é¥°å™¨
- é”™è¯¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- å‚æ•°éªŒè¯å·¥å…·
- æ‰¹é‡æ“ä½œé”™è¯¯æ”¶é›†

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from modules.error_handler import handle_errors, ErrorContext

# è£…é¥°å™¨æ–¹å¼
@handle_errors("æ•°æ®åŠ è½½å¤±è´¥", return_value=pd.DataFrame())
def load_data(symbol):
    # your code here
    pass

# ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–¹å¼
with ErrorContext("æ‰¹é‡å¤„ç†è‚¡ç¥¨") as ctx:
    for symbol in symbols:
        ctx.execute(lambda: process_stock(symbol), f"å¤„ç†{symbol}")
    
    if ctx.has_errors():
        ctx.show_errors()
```

**ä¼˜åŠ¿**ï¼š
- é”™è¯¯å¤„ç†é€»è¾‘å¤ç”¨
- ç»Ÿä¸€çš„é”™è¯¯å±•ç¤º
- ä¾¿äºè°ƒè¯•å’Œæ—¥å¿—è®°å½•

### 4. âœ… æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–

#### æ–°å¢æ¨¡å—ï¼š`modules/logger_config.py`

**åŠŸèƒ½**ï¼š
- ä½¿ç”¨ `loguru` æ›¿ä»£æ ‡å‡† logging
- å½©è‰²æ§åˆ¶å°è¾“å‡º
- è‡ªåŠ¨æ—¥å¿—è½®è½¬å’Œå‹ç¼©
- JSON æ ¼å¼æ—¥å¿—ï¼ˆä¾¿äºåˆ†æï¼‰
- åˆ†çº§æ—¥å¿—æ–‡ä»¶

**æ—¥å¿—æ–‡ä»¶ç»“æ„**ï¼š
```
logs/
â”œâ”€â”€ app_2025-01-13.log      # æ‰€æœ‰æ—¥å¿—
â”œâ”€â”€ error_2025-01-13.log    # é”™è¯¯æ—¥å¿—
â””â”€â”€ app_2025-01-13.json     # JSONæ ¼å¼æ—¥å¿—
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from modules.logger_config import logger

logger.info("è¿™æ˜¯ä¸€æ¡ä¿¡æ¯")
logger.warning("è¿™æ˜¯ä¸€æ¡è­¦å‘Š")
logger.error("è¿™æ˜¯ä¸€æ¡é”™è¯¯")
```

**ä¼˜åŠ¿**ï¼š
- æ›´å¥½çš„æ—¥å¿—æ ¼å¼
- è‡ªåŠ¨ç®¡ç†æ—¥å¿—æ–‡ä»¶
- ä¾¿äºé—®é¢˜æ’æŸ¥

---

## ğŸ¯ æ¶æ„è®¾è®¡åŸåˆ™

### 1. å•ä¸€èŒè´£åŸåˆ™ï¼ˆSRPï¼‰

æ¯ä¸ªæ¨¡å—åªè´Ÿè´£ä¸€ä¸ªåŠŸèƒ½ï¼š
- `config_manager.py` - é…ç½®ç®¡ç†
- `error_handler.py` - é”™è¯¯å¤„ç†
- `logger_config.py` - æ—¥å¿—è®°å½•
- `data_loader.py` - æ•°æ®åŠ è½½

### 2. ä¾èµ–å€’ç½®åŸåˆ™ï¼ˆDIPï¼‰

é«˜å±‚æ¨¡å—ä¸ä¾èµ–ä½å±‚æ¨¡å—ï¼Œéƒ½ä¾èµ–æŠ½è±¡ï¼š
```python
# ä¸å¥½çš„åšæ³•
def get_data():
    # ç›´æ¥ä¾èµ–å…·ä½“å®ç°
    return TushareAPI().fetch()

# å¥½çš„åšæ³•
def get_data(data_source: DataSource):
    # ä¾èµ–æŠ½è±¡æ¥å£
    return data_source.fetch()
```

### 3. å¼€é—­åŸåˆ™ï¼ˆOCPï¼‰

å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­ï¼š
```python
# é…ç½®ç®¡ç†æ”¯æŒæ‰©å±•
class Config:
    @classmethod
    def get_custom_config(cls, key: str, default=None):
        return os.getenv(key, default)
```

---

## ğŸ“Š æ¨¡å—ä¾èµ–å…³ç³»

```
streamlit_app.py
    â†“
modules/app.py
    â†“
â”œâ”€â”€ modules/config_manager.py (é…ç½®)
â”œâ”€â”€ modules/logger_config.py (æ—¥å¿—)
â”œâ”€â”€ modules/error_handler.py (é”™è¯¯å¤„ç†)
â”œâ”€â”€ modules/data_loader.py (æ•°æ®åŠ è½½)
â”‚   â†“
â”‚   â”œâ”€â”€ aitrader_core/datafeed/tushare_loader.py
â”‚   â”œâ”€â”€ aitrader_core/datafeed/akshare_loader.py
â”‚   â””â”€â”€ aitrader_core/datafeed/csv_dataloader.py
â””â”€â”€ modules/frontend.py (ç•Œé¢)
```

---

## ğŸ”„ æ•°æ®æµè®¾è®¡

### 1. é…ç½®åŠ è½½æµç¨‹

```
å¯åŠ¨åº”ç”¨
    â†“
åŠ è½½ .env æ–‡ä»¶
    â†“
åˆå§‹åŒ– Config ç±»
    â†“
éªŒè¯å¿…è¦é…ç½®
    â†“
åˆ›å»ºå¿…è¦ç›®å½•
    â†“
åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
```

### 2. æ•°æ®è·å–æµç¨‹

```
ç”¨æˆ·è¯·æ±‚æ•°æ®
    â†“
æ£€æŸ¥ç¼“å­˜
    â†“ (æœªå‘½ä¸­)
é€‰æ‹©æ•°æ®æº
    â†“
é™æµæ§åˆ¶
    â†“
å‘èµ·è¯·æ±‚
    â†“
é”™è¯¯å¤„ç†
    â†“
ä¿å­˜ç¼“å­˜
    â†“
è¿”å›æ•°æ®
```

### 3. é”™è¯¯å¤„ç†æµç¨‹

```
å‘ç”Ÿå¼‚å¸¸
    â†“
æ•è·å¼‚å¸¸
    â†“
è®°å½•æ—¥å¿—
    â†“
æ˜¾ç¤ºç”¨æˆ·æç¤º
    â†“
è¿”å›é»˜è®¤å€¼/é‡è¯•
```

---

## ğŸ› ï¸ ä½¿ç”¨æ–°æ¶æ„çš„ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šåˆ›å»ºæ–°çš„æ•°æ®åŠ è½½æ¨¡å—

```python
"""
æ–°æ•°æ®æºæ¨¡å—ç¤ºä¾‹
"""
from modules.config_manager import Config
from modules.logger_config import logger
from modules.error_handler import handle_errors
import pandas as pd

class NewDataSource:
    """æ–°æ•°æ®æº"""
    
    def __init__(self):
        self.api_key = Config.get_custom_config('NEW_API_KEY')
        logger.info("åˆå§‹åŒ–æ–°æ•°æ®æº")
    
    @handle_errors("æ•°æ®è·å–å¤±è´¥", return_value=pd.DataFrame())
    def fetch_data(self, symbol: str) -> pd.DataFrame:
        """è·å–æ•°æ®"""
        logger.info(f"è·å– {symbol} æ•°æ®")
        
        # å®ç°æ•°æ®è·å–é€»è¾‘
        # ...
        
        logger.info(f"æˆåŠŸè·å– {symbol} æ•°æ®")
        return df
```

### ç¤ºä¾‹ 2ï¼šæ‰¹é‡å¤„ç†ä»»åŠ¡

```python
from modules.error_handler import ErrorContext
from modules.logger_config import logger

def batch_update_stocks(symbols: list):
    """æ‰¹é‡æ›´æ–°è‚¡ç¥¨æ•°æ®"""
    
    with ErrorContext("æ‰¹é‡æ›´æ–°è‚¡ç¥¨") as ctx:
        for symbol in symbols:
            ctx.execute(
                lambda: update_stock(symbol),
                f"æ›´æ–° {symbol}"
            )
        
        # æ˜¾ç¤ºç»“æœ
        logger.info(ctx.get_summary())
        
        if ctx.has_errors():
            ctx.show_errors()
```

### ç¤ºä¾‹ 3ï¼šä½¿ç”¨é…ç½®ç®¡ç†

```python
from modules.config_manager import Config

# è·å–é…ç½®
data_dir = Config.STOCK_DATA_DIR
cache_ttl = Config.CACHE_TTL_MINUTES

# éªŒè¯é…ç½®
Config.validate()

# æ‰“å°é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰
if Config.DEBUG:
    Config.print_config()
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¼“å­˜ç­–ç•¥

```python
# ä½¿ç”¨æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
from modules.smart_data_manager import smart_data_manager

@smart_data_manager.cached_request(cache_type='daily_data')
def get_stock_data(symbol):
    # æ•°æ®è·å–é€»è¾‘
    pass
```

### 2. å¼‚æ­¥å¤„ç†

```python
# ä½¿ç”¨å¼‚æ­¥æ•°æ®å¤„ç†å™¨
from modules.async_data_processor import async_processor

@async_processor.async_fetch(show_progress=True)
def fetch_multiple_stocks(symbols):
    # æ‰¹é‡è·å–é€»è¾‘
    pass
```

### 3. æ•°æ®åº“ä¼˜åŒ–ï¼ˆæœªæ¥ï¼‰

```python
# ä½¿ç”¨æ•°æ®åº“å­˜å‚¨å†å²æ•°æ®
from modules.database import StockDB

db = StockDB(Config.DATABASE_URL)
df = db.query_stock_data(symbol, start_date, end_date)
```

---

## ğŸ” ä»£ç è´¨é‡å·¥å…·

### 1. ä»£ç æ ¼å¼åŒ–

```bash
# å®‰è£…å·¥å…·
pip install black isort

# æ ¼å¼åŒ–ä»£ç 
black modules/ aitrader_core/
isort modules/ aitrader_core/
```

### 2. ä»£ç æ£€æŸ¥

```bash
# å®‰è£…å·¥å…·
pip install flake8 pylint

# æ£€æŸ¥ä»£ç 
flake8 modules/ aitrader_core/
pylint modules/ aitrader_core/
```

### 3. ç±»å‹æ£€æŸ¥

```bash
# å®‰è£…å·¥å…·
pip install mypy

# ç±»å‹æ£€æŸ¥
mypy modules/ aitrader_core/
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```python
# tests/unit/test_config_manager.py
import pytest
from modules.config_manager import Config

def test_config_validation():
    """æµ‹è¯•é…ç½®éªŒè¯"""
    Config.validate()
    assert Config.TUSHARE_TOKEN is not None

def test_directory_creation():
    """æµ‹è¯•ç›®å½•åˆ›å»º"""
    Config.ensure_dirs()
    assert Config.DATA_DIR.exists()
```

### 2. é›†æˆæµ‹è¯•

```python
# tests/integration/test_data_flow.py
def test_data_fetch_flow():
    """æµ‹è¯•å®Œæ•´æ•°æ®è·å–æµç¨‹"""
    # 1. é…ç½®åŠ è½½
    # 2. æ•°æ®æºåˆå§‹åŒ–
    # 3. æ•°æ®è·å–
    # 4. ç¼“å­˜éªŒè¯
    pass
```

### 3. æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_cache.py
import time

def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆæ— ç¼“å­˜ï¼‰
    start = time.time()
    data1 = get_data()
    time1 = time.time() - start
    
    # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆæœ‰ç¼“å­˜ï¼‰
    start = time.time()
    data2 = get_data()
    time2 = time.time() - start
    
    # ç¼“å­˜åº”è¯¥æ›´å¿«
    assert time2 < time1 * 0.1
```

---

## ğŸ“ å¼€å‘è§„èŒƒ

### 1. å‘½åè§„èŒƒ

```python
# æ¨¡å—åï¼šå°å†™+ä¸‹åˆ’çº¿
config_manager.py

# ç±»åï¼šå¤§é©¼å³°
class ConfigManager:
    pass

# å‡½æ•°åï¼šå°å†™+ä¸‹åˆ’çº¿
def get_stock_data():
    pass

# å¸¸é‡ï¼šå¤§å†™+ä¸‹åˆ’çº¿
MAX_RETRY_TIMES = 3

# ç§æœ‰æ–¹æ³•ï¼šå‰ç¼€ä¸‹åˆ’çº¿
def _internal_method():
    pass
```

### 2. æ–‡æ¡£å­—ç¬¦ä¸²

```python
def fetch_data(symbol: str, start_date: str) -> pd.DataFrame:
    """
    è·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600519.SH'
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'
    
    Returns:
        DataFrame: åŒ…å« OHLCV æ•°æ®
    
    Raises:
        ValueError: å¦‚æœè‚¡ç¥¨ä»£ç æ— æ•ˆ
        APIError: å¦‚æœ API è°ƒç”¨å¤±è´¥
    
    Example:
        >>> df = fetch_data('600519.SH', '20200101')
        >>> print(df.head())
    """
    pass
```

### 3. ç±»å‹æ³¨è§£

```python
from typing import List, Dict, Optional
import pandas as pd

def process_stocks(
    symbols: List[str],
    config: Dict[str, any],
    cache: Optional[bool] = True
) -> pd.DataFrame:
    """å¤„ç†è‚¡ç¥¨æ•°æ®"""
    pass
```

---

## ğŸš€ æœªæ¥ä¼˜åŒ–æ–¹å‘

### 1. æ•°æ®åº“æ”¯æŒ

- [ ] SQLite æœ¬åœ°å­˜å‚¨
- [ ] PostgreSQL ç”Ÿäº§ç¯å¢ƒ
- [ ] Redis ç¼“å­˜åŠ é€Ÿ

### 2. å¾®æœåŠ¡æ¶æ„

- [ ] æ•°æ®æœåŠ¡ç‹¬ç«‹
- [ ] ç­–ç•¥æœåŠ¡ç‹¬ç«‹
- [ ] API ç½‘å…³

### 3. å®¹å™¨åŒ–éƒ¨ç½²

- [ ] Docker é•œåƒä¼˜åŒ–
- [ ] Kubernetes ç¼–æ’
- [ ] CI/CD è‡ªåŠ¨åŒ–

### 4. ç›‘æ§å‘Šè­¦

- [ ] Prometheus ç›‘æ§
- [ ] Grafana å¯è§†åŒ–
- [ ] å‘Šè­¦è§„åˆ™é…ç½®

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Python æœ€ä½³å®è·µ](https://docs.python-guide.org/)
- [Clean Code in Python](https://github.com/zedr/clean-code-python)
- [Streamlit æ–‡æ¡£](https://docs.streamlit.io/)
- [Loguru æ–‡æ¡£](https://loguru.readthedocs.io/)

---

**æœ€åæ›´æ–°**ï¼š2025-01-13
