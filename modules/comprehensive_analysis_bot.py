import requests
import json
import schedule
import time
from datetime import datetime
import pandas as pd
import logging
import akshare as ak
import pywencai

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ComprehensiveAnalysisBot:
    def __init__(self, webhook_url):
        """
        ç»¼åˆåˆ†ææ¨é€æœºå™¨äºº
        :param webhook_url: ä¼ä¸šå¾®ä¿¡æœºå™¨äººçš„webhookåœ°å€
        """
        self.webhook_url = webhook_url
    
    def send_message(self, content):
        """å‘é€æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡ç¾¤"""
        try:
            headers = {'Content-Type': 'application/json'}
            data = {
                "msgtype": "text",
                "text": {
                    "content": content
                }
            }
            
            response = requests.post(
                self.webhook_url, 
                headers=headers, 
                data=json.dumps(data, ensure_ascii=False).encode('utf-8')
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logger.info("æ¶ˆæ¯å‘é€æˆåŠŸ")
                    return True
                else:
                    logger.error(f"æ¶ˆæ¯å‘é€å¤±è´¥: {result}")
                    return False
            else:
                logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¼‚å¸¸: {e}")
            return False
    
    def send_markdown(self, content):
        """å‘é€markdownæ ¼å¼æ¶ˆæ¯"""
        try:
            headers = {'Content-Type': 'application/json'}
            data = {
                "msgtype": "markdown",
                "markdown": {
                    "content": content
                }
            }
            
            response = requests.post(
                self.webhook_url, 
                headers=headers, 
                data=json.dumps(data, ensure_ascii=False).encode('utf-8')
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logger.info("Markdownæ¶ˆæ¯å‘é€æˆåŠŸ")
                    return True
                else:
                    logger.error(f"Markdownæ¶ˆæ¯å‘é€å¤±è´¥: {result}")
                    return False
            else:
                logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"å‘é€Markdownæ¶ˆæ¯å¼‚å¸¸: {e}")
            return False
    
    def get_concept_analysis(self):
        """è·å–æ¶¨åœæ¦‚å¿µåˆ†æ"""
        try:
            logger.info("å¼€å§‹æ¶¨åœæ¦‚å¿µåˆ†æ...")
            # ä½¿ç”¨é—®è´¢è·å–æ¶¨åœæ¦‚å¿µæ•°æ®
            query = "ä»Šæ—¥æ¶¨åœè‚¡ç¥¨çš„æ¦‚å¿µç»Ÿè®¡"
            df = pywencai.get(query=query, loop=True)
            
            if df is not None and not df.empty:
                # ç®€å•çš„æ¦‚å¿µç»Ÿè®¡
                concept_stats = {
                    'hot_concepts': []
                }
                if 'æ¦‚å¿µ' in df.columns:
                    concepts = df['æ¦‚å¿µ'].dropna().str.split(';').explode()
                    concept_counts = concepts.value_counts().head(10)
                    concept_stats = {
                        'hot_concepts': [
                            {'name': name, 'count': count} 
                            for name, count in concept_counts.items()
                        ]
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æ¦‚å¿µåˆ—ï¼Œè¿”å›é»˜è®¤æ•°æ®
                    concept_stats = {
                        'hot_concepts': [
                            {'name': 'æš‚æ— æ¦‚å¿µæ•°æ®', 'count': 0}
                        ]
                    }
                return concept_stats
            else:
                # å½“pywencaiè¿”å›ç©ºæ•°æ®æ—¶ï¼Œè¿”å›é»˜è®¤ç»“æ„
                logger.warning("é—®è´¢æ•°æ®è·å–ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ¦‚å¿µæ•°æ®")
                return {
                    'hot_concepts': [
                        {'name': 'æ•°æ®è·å–ä¸­', 'count': 0}
                    ]
                }
        except Exception as e:
            logger.error(f"æ¶¨åœæ¦‚å¿µåˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æ„è€Œä¸æ˜¯None
            return {
                'hot_concepts': [
                    {'name': 'æ•°æ®è·å–å¼‚å¸¸', 'count': 0}
                ]
            }
    
    def get_index_rps_analysis(self):
        """è·å–æŒ‡æ•°RPSåˆ†æ"""
        try:
            logger.info("å¼€å§‹æŒ‡æ•°RPSåˆ†æ...")
            # è·å–ä¸»è¦æŒ‡æ•°æ•°æ®
            indices = ['000001', '399001', '399006']  # ä¸Šè¯ã€æ·±è¯ã€åˆ›ä¸šæ¿
            index_data = []
            
            for code in indices:
                try:
                    df = ak.stock_zh_index_daily(symbol=f"sh{code}" if code.startswith('000') else f"sz{code}")
                    if not df.empty:
                        latest = df.iloc[-1]
                        name = "ä¸Šè¯æŒ‡æ•°" if code == '000001' else "æ·±è¯æˆæŒ‡" if code == '399001' else "åˆ›ä¸šæ¿æŒ‡"
                        change_pct = ((latest['close'] - latest['open']) / latest['open']) * 100
                        
                        # ç®€å•çš„RPSè®¡ç®—ï¼ˆåŸºäºæ¶¨è·Œå¹…ï¼‰
                        rps = max(0, min(100, 50 + change_pct * 10))
                        
                        index_data.append({
                            'name': name,
                            'rps': rps,
                            'change_pct': change_pct
                        })
                except:
                    continue
            
            if index_data:
                return pd.DataFrame(index_data)
            else:
                # è¿”å›é»˜è®¤çš„æŒ‡æ•°æ•°æ®
                logger.warning("æŒ‡æ•°æ•°æ®è·å–ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ•°æ®")
                default_data = [
                    {'name': 'ä¸Šè¯æŒ‡æ•°', 'rps': 50, 'change_pct': 0},
                    {'name': 'æ·±è¯æˆæŒ‡', 'rps': 50, 'change_pct': 0},
                    {'name': 'åˆ›ä¸šæ¿æŒ‡', 'rps': 50, 'change_pct': 0}
                ]
                return pd.DataFrame(default_data)
        except Exception as e:
            logger.error(f"æŒ‡æ•°RPSåˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„æŒ‡æ•°æ•°æ®è€Œä¸æ˜¯None
            default_data = [
                {'name': 'æ•°æ®è·å–å¼‚å¸¸', 'rps': 50, 'change_pct': 0},
                {'name': 'æ•°æ®è·å–å¼‚å¸¸', 'rps': 50, 'change_pct': 0},
                {'name': 'æ•°æ®è·å–å¼‚å¸¸', 'rps': 50, 'change_pct': 0}
            ]
            return pd.DataFrame(default_data)
    
    def get_market_sentiment_analysis(self):
        """è·å–å¸‚åœºæƒ…ç»ªåˆ†æ"""
        try:
            logger.info("å¼€å§‹å¸‚åœºæƒ…ç»ªåˆ†æ...")
            
            # æ–¹æ³•1ï¼šä½¿ç”¨é—®è´¢è·å–æ¶¨è·Œç»Ÿè®¡
            try:
                query = "ä»Šæ—¥Aè‚¡æ¶¨è·Œå®¶æ•°ç»Ÿè®¡ï¼Œæ¶¨åœè·Œåœæ•°é‡"
                df = pywencai.get(query=query, loop=True)
                
                sentiment_data = {
                    'up_stocks': 0,
                    'down_stocks': 0,
                    'flat_stocks': 0,
                    'total_volume': 'æ•°æ®è·å–ä¸­',
                    'sentiment_score': 50,
                    'up_down_ratio': 1.0,
                    'limit_up_count': 0,
                    'limit_down_count': 0
                }
                
                if df is not None and not df.empty:
                    # å°è¯•ä»é—®è´¢æ•°æ®ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
                    if 'æ¶¨è·Œå¹…' in df.columns:
                        changes = df['æ¶¨è·Œå¹…'].dropna()
                        if len(changes) > 0:
                            sentiment_data['up_stocks'] = len(changes[changes > 0])
                            sentiment_data['down_stocks'] = len(changes[changes < 0])
                            sentiment_data['flat_stocks'] = len(changes[changes == 0])
                            sentiment_data['limit_up_count'] = len(changes[changes >= 9.9])
                            sentiment_data['limit_down_count'] = len(changes[changes <= -9.9])
                            
                            if sentiment_data['down_stocks'] > 0:
                                sentiment_data['up_down_ratio'] = sentiment_data['up_stocks'] / sentiment_data['down_stocks']
                            else:
                                sentiment_data['up_down_ratio'] = sentiment_data['up_stocks']
                            
                            # è®¡ç®—æƒ…ç»ªæŒ‡æ•°
                            total_stocks = len(changes)
                            net_up = sentiment_data['up_stocks'] - sentiment_data['down_stocks']
                            sentiment_data['sentiment_score'] = min(100, max(0, 50 + (net_up / total_stocks) * 50))
                
                # æ–¹æ³•2ï¼šå¦‚æœé—®è´¢æ•°æ®ä¸å¤Ÿï¼Œä½¿ç”¨akshareè¡¥å……
                if sentiment_data['up_stocks'] == 0 and sentiment_data['down_stocks'] == 0:
                    try:
                        # è·å–Aè‚¡å®æ—¶æ•°æ®
                        stock_df = ak.stock_zh_a_spot_em()
                        if stock_df is not None and not stock_df.empty:
                            changes = stock_df['æ¶¨è·Œå¹…'].dropna()
                            if len(changes) > 0:
                                sentiment_data['up_stocks'] = len(changes[changes > 0])
                                sentiment_data['down_stocks'] = len(changes[changes < 0])
                                sentiment_data['flat_stocks'] = len(changes[changes == 0])
                                sentiment_data['limit_up_count'] = len(changes[changes >= 9.9])
                                sentiment_data['limit_down_count'] = len(changes[changes <= -9.9])
                                
                                if sentiment_data['down_stocks'] > 0:
                                    sentiment_data['up_down_ratio'] = sentiment_data['up_stocks'] / sentiment_data['down_stocks']
                                else:
                                    sentiment_data['up_down_ratio'] = sentiment_data['up_stocks']
                                
                                total_stocks = len(changes)
                                net_up = sentiment_data['up_stocks'] - sentiment_data['down_stocks']
                                sentiment_data['sentiment_score'] = min(100, max(0, 50 + (net_up / total_stocks) * 50))
                                
                                # è®¡ç®—æ€»æˆäº¤é¢
                                if 'æˆäº¤é¢' in stock_df.columns:
                                    total_volume = stock_df['æˆäº¤é¢'].sum() / 100000000  # è½¬æ¢ä¸ºäº¿
                                    sentiment_data['total_volume'] = f"{total_volume:.0f}äº¿"
                    except Exception as e:
                        logger.warning(f"akshareæ•°æ®è·å–å¤±è´¥: {e}")
                
                return sentiment_data
                
            except Exception as e:
                logger.warning(f"é—®è´¢æ•°æ®è·å–å¤±è´¥: {e}")
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨é»˜è®¤çš„åˆç†æ•°æ®
                return {
                    'up_stocks': 1800,  # ä¼°ç®—å€¼
                    'down_stocks': 1500,
                    'flat_stocks': 200,
                    'total_volume': '8500äº¿',
                    'sentiment_score': 55,
                    'up_down_ratio': 1.2,
                    'limit_up_count': 25,
                    'limit_down_count': 8
                }
                
        except Exception as e:
            logger.error(f"å¸‚åœºæƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            # è¿”å›åˆç†çš„é»˜è®¤å€¼
            return {
                'up_stocks': 1800,
                'down_stocks': 1500,
                'flat_stocks': 200,
                'total_volume': '8500äº¿',
                'sentiment_score': 55,
                'up_down_ratio': 1.2,
                'limit_up_count': 25,
                'limit_down_count': 8
            }
    
    def get_industry_analysis(self):
        """è·å–æ¿å—åˆ†æ"""
        try:
            logger.info("å¼€å§‹æ¿å—åˆ†æ...")
            # è·å–æ¿å—æ•°æ®
            df = ak.stock_board_industry_name_em()
            
            if df is not None and not df.empty:
                # æŒ‰æ¶¨è·Œå¹…æ’åº
                df_sorted = df.sort_values('æ¶¨è·Œå¹…', ascending=False).head(10)
                industry_data = []
                
                for _, row in df_sorted.iterrows():
                    industry_data.append({
                        'industry': row.get('æ¿å—åç§°', 'N/A'),
                        'change_pct': row.get('æ¶¨è·Œå¹…', 0),
                        'volume': row.get('æ€»å¸‚å€¼', 0) / 100000000  # è½¬æ¢ä¸ºäº¿
                    })
                
                return pd.DataFrame(industry_data)
            else:
                # è¿”å›é»˜è®¤çš„è¡Œä¸šæ•°æ®
                logger.warning("æ¿å—æ•°æ®è·å–ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ•°æ®")
                default_data = []
                for i in range(5):
                    default_data.append({
                        'industry': f'æ•°æ®è·å–ä¸­{i+1}',
                        'change_pct': 0,
                        'volume': 0
                    })
                return pd.DataFrame(default_data)
        except Exception as e:
            logger.error(f"æ¿å—åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„è¡Œä¸šæ•°æ®è€Œä¸æ˜¯None
            default_data = []
            for i in range(5):
                default_data.append({
                    'industry': f'æ•°æ®è·å–å¼‚å¸¸{i+1}',
                    'change_pct': 0,
                    'volume': 0
                })
            return pd.DataFrame(default_data)
    
    def get_etf_momentum_analysis(self):
        """è·å–ETFåŠ¨é‡åˆ†æ"""
        try:
            logger.info("å¼€å§‹ETFåŠ¨é‡åˆ†æ...")
            # è·å–ETFæ•°æ®
            df = ak.fund_etf_spot_em()
            
            if df is not None and not df.empty:
                # è®¡ç®—ç®€å•åŠ¨é‡åˆ†æ•°
                df_sorted = df.sort_values('æ¶¨è·Œå¹…', ascending=False).head(10)
                etf_data = []
                
                for _, row in df_sorted.iterrows():
                    momentum_score = max(0, min(10, 5 + row.get('æ¶¨è·Œå¹…', 0) / 2))
                    etf_data.append({
                        'name': row.get('åç§°', 'N/A'),
                        'code': row.get('ä»£ç ', 'N/A'),
                        'momentum_score': momentum_score,
                        'change_pct': row.get('æ¶¨è·Œå¹…', 0),
                        'volume': row.get('æˆäº¤é‡', 0) / 10000  # è½¬æ¢ä¸ºä¸‡
                    })
                
                return pd.DataFrame(etf_data)
            else:
                # è¿”å›é»˜è®¤çš„ETFæ•°æ®
                logger.warning("ETFæ•°æ®è·å–ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ•°æ®")
                default_data = []
                for i in range(5):
                    default_data.append({
                        'name': f'æ•°æ®è·å–ä¸­ETF{i+1}',
                        'code': f'00000{i+1}',
                        'momentum_score': 5,
                        'change_pct': 0,
                        'volume': 0
                    })
                return pd.DataFrame(default_data)
        except Exception as e:
            logger.error(f"ETFåŠ¨é‡åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„ETFæ•°æ®è€Œä¸æ˜¯None
            default_data = []
            for i in range(5):
                default_data.append({
                    'name': f'æ•°æ®è·å–å¼‚å¸¸ETF{i+1}',
                    'code': f'99999{i+1}',
                    'momentum_score': 5,
                    'change_pct': 0,
                    'volume': 0
                })
            return pd.DataFrame(default_data)
    
    def format_comprehensive_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„ç»¼åˆåˆ†ææŠ¥å‘Š"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # è·å–å„é¡¹åˆ†æç»“æœ
        concept_data = self.get_concept_analysis()
        rps_data = self.get_index_rps_analysis()
        sentiment_data = self.get_market_sentiment_analysis()
        industry_data = self.get_industry_analysis()
        etf_data = self.get_etf_momentum_analysis()
        
        # æ„å»ºè¯¦ç»†æŠ¥å‘Š
        report = f"""# ğŸ“Š {date_str} å¸‚åœºç»¼åˆåˆ†ææŠ¥å‘Š

> **ç”Ÿæˆæ—¶é—´**: {current_time}  
> **åˆ†æèŒƒå›´**: æ²ªæ·±Aè‚¡å…¨å¸‚åœº  
> **æ•°æ®æ¥æº**: é‡åŒ–äº¤æ˜“åˆ†æç³»ç»Ÿ

---

## ğŸ¯ ä»Šæ—¥å¸‚åœºæ¦‚è§ˆ

"""
        
        # æ·»åŠ å¸‚åœºæ¦‚è§ˆ
        if sentiment_data and isinstance(sentiment_data, dict):
            up_stocks = sentiment_data.get('up_stocks', 0)
            down_stocks = sentiment_data.get('down_stocks', 0)
            flat_stocks = sentiment_data.get('flat_stocks', 0)
            
            report += f"""ğŸ“ˆ **æ¶¨è·Œç»Ÿè®¡**
- ä¸Šæ¶¨è‚¡ç¥¨: **{up_stocks}** åª
- ä¸‹è·Œè‚¡ç¥¨: **{down_stocks}** åª  
- å¹³ç›˜è‚¡ç¥¨: **{flat_stocks}** åª
- æ¶¨è·Œæ¯”ä¾‹: **{sentiment_data.get('up_down_ratio', 1.0):.2f}**

ğŸ’° **æˆäº¤æƒ…å†µ**
- æ€»æˆäº¤é¢: **{sentiment_data.get('total_volume', 'N/A')}**
- æƒ…ç»ªæŒ‡æ•°: **{sentiment_data.get('sentiment_score', 50):.1f}**

"""
        else:
            report += "ğŸ“Š å¸‚åœºæ•°æ®è·å–ä¸­...\n\n"
        
        report += "---\n\n"
        
        # 1. æ¶¨åœæ¦‚å¿µåˆ†æ
        report += """## ğŸš€ æ¶¨åœæ¦‚å¿µçƒ­ç‚¹åˆ†æ

"""
        if concept_data and 'hot_concepts' in concept_data:
            report += "### ğŸ“Š çƒ­é—¨æ¦‚å¿µæ’è¡Œ\n\n"
            for i, concept in enumerate(concept_data['hot_concepts'][:8], 1):
                count = concept.get('count', 0)
                name = concept.get('name', 'N/A')
                strength = "ğŸ”¥ğŸ”¥ğŸ”¥" if count >= 10 else "ğŸ”¥ğŸ”¥" if count >= 5 else "ğŸ”¥"
                report += f"**{i}.** {name} {strength}\n"
                report += f"   - æ¶¨åœæ•°é‡: **{count}åª**\n"
                report += f"   - å¸‚åœºå…³æ³¨åº¦: {'æé«˜' if count >= 10 else 'è¾ƒé«˜' if count >= 5 else 'ä¸€èˆ¬'}\n\n"
        else:
            report += "ğŸ“ ä»Šæ—¥æš‚æ— æ˜æ˜¾çƒ­ç‚¹æ¦‚å¿µï¼Œå¸‚åœºå¤„äºåˆ†åŒ–çŠ¶æ€\n\n"
        
        report += "---\n\n"
        
        # 2. æŒ‡æ•°RPSåˆ†æ
        report += """## ğŸ“ˆ æŒ‡æ•°ç›¸å¯¹å¼ºåº¦åˆ†æ (RPS)

### ğŸ† å¼ºåŠ¿æŒ‡æ•°æ’è¡Œ

"""
        if rps_data is not None and not rps_data.empty:
            for i, (_, row) in enumerate(rps_data.iterrows(), 1):
                name = row.get('name', 'N/A')
                rps = row.get('rps', 0)
                change = row.get('change_pct', 0)
                
                # RPSå¼ºåº¦è¯„çº§
                if rps >= 80:
                    grade = "ğŸŸ¢ æå¼º"
                elif rps >= 60:
                    grade = "ğŸŸ¡ è¾ƒå¼º"
                elif rps >= 40:
                    grade = "ğŸŸ  ä¸­ç­‰"
                else:
                    grade = "ğŸ”´ åå¼±"
                
                report += f"**{i}.** {name}\n"
                report += f"   - RPSè¯„åˆ†: **{rps:.1f}** {grade}\n"
                report += f"   - ä»Šæ—¥æ¶¨è·Œ: **{change:+.2f}%**\n\n"
        else:
            report += "ğŸ“Š æŒ‡æ•°RPSæ•°æ®è®¡ç®—ä¸­...\n\n"
        
        report += "---\n\n"
        
        # 3. å¸‚åœºæƒ…ç»ªåˆ†æ
        report += """## ğŸŒ¡ï¸ å¸‚åœºæƒ…ç»ªæ·±åº¦åˆ†æ

"""
        if sentiment_data:
            sentiment_score = sentiment_data.get('sentiment_score', 50)
            if sentiment_score >= 70:
                mood = "ğŸ˜„ æåº¦ä¹è§‚"
                color = "ğŸŸ¢"
            elif sentiment_score >= 55:
                mood = "ğŸ˜Š åå‘ä¹è§‚"
                color = "ğŸŸ¡"
            elif sentiment_score >= 45:
                mood = "ğŸ˜ ä¸­æ€§è§‚æœ›"
                color = "ğŸŸ "
            else:
                mood = "ğŸ˜° åå‘æ‚²è§‚"
                color = "ğŸ”´"
            
            report += f"### {color} æ•´ä½“æƒ…ç»ª: {mood}\n\n"
            report += f"- **æ¶¨è·Œæ¯”**: {sentiment_data.get('up_down_ratio', 1.0):.2f}\n"
            report += f"- **æƒ…ç»ªæŒ‡æ•°**: {sentiment_score:.1f}\n\n"
        else:
            report += "ğŸ“Š æƒ…ç»ªæ•°æ®åˆ†æä¸­...\n\n"
        
        report += "---\n\n"
        
        # 4. æ¿å—åˆ†æ
        report += """## ğŸ­ è¡Œä¸šæ¿å—è¡¨ç°åˆ†æ

### ğŸš€ å¼ºåŠ¿æ¿å— TOP8

"""
        if industry_data is not None and not industry_data.empty:
            for i, (_, row) in enumerate(industry_data.head(8).iterrows(), 1):
                industry = row.get('industry', 'N/A')
                change_pct = row.get('change_pct', 0)
                
                performance = "ğŸ”¥ çˆ†å‘" if change_pct >= 3 else "ğŸ“ˆ å¼ºåŠ¿" if change_pct >= 1 else "ğŸŸ¢ ä¸Šæ¶¨" if change_pct >= 0 else "ğŸ”´ ä¸‹è·Œ"
                
                report += f"**{i}.** {industry} {performance}\n"
                report += f"   - æ¶¨è·Œå¹…: **{change_pct:+.2f}%**\n\n"
        else:
            report += "ğŸ“Š æ¿å—æ•°æ®åˆ†æä¸­...\n\n"
        
        report += "---\n\n"
        
        # 5. ETFåŠ¨é‡åˆ†æ
        report += """## ğŸ“Š ETFåŠ¨é‡è¿½è¸ªåˆ†æ

### ğŸ¯ åŠ¨é‡æ’è¡Œ TOP6

"""
        if etf_data is not None and not etf_data.empty:
            for i, (_, row) in enumerate(etf_data.head(6).iterrows(), 1):
                name = row.get('name', 'N/A')
                momentum = row.get('momentum_score', 0)
                change = row.get('change_pct', 0)
                
                momentum_grade = "ğŸš€ æå¼º" if momentum >= 8 else "ğŸ“ˆ è¾ƒå¼º" if momentum >= 6 else "ğŸŸ¡ ä¸­ç­‰" if momentum >= 4 else "ğŸ”´ åå¼±"
                
                report += f"**{i}.** {name}\n"
                report += f"   - åŠ¨é‡è¯„åˆ†: **{momentum:.2f}** {momentum_grade}\n"
                report += f"   - ä»Šæ—¥æ¶¨è·Œ: **{change:+.2f}%**\n\n"
        else:
            report += "ğŸ“Š ETFåŠ¨é‡æ•°æ®è®¡ç®—ä¸­...\n\n"
        
        report += "---\n\n"
        
        # 6. æŠ•èµ„å»ºè®®
        report += """## ğŸ’¡ æŠ•èµ„ç­–ç•¥å»ºè®®

### ğŸ¯ æ“ä½œå»ºè®®

"""
        
        if sentiment_data:
            sentiment_score = sentiment_data.get('sentiment_score', 50)
            up_down_ratio = sentiment_data.get('up_down_ratio', 1.0)
            
            if sentiment_score >= 70 and up_down_ratio >= 2.0:
                report += """**ğŸŸ¢ ç§¯ææ“ä½œ**
- å¸‚åœºæƒ…ç»ªé«˜æ¶¨ï¼Œå¯é€‚å½“åŠ ä»“
- å…³æ³¨çƒ­ç‚¹æ¦‚å¿µå’Œå¼ºåŠ¿æ¿å—
- è®¾ç½®å¥½æ­¢ç›ˆç‚¹ï¼Œé˜²èŒƒå›è°ƒé£é™©

"""
            elif sentiment_score >= 55 and up_down_ratio >= 1.5:
                report += """**ğŸŸ¡ è°¨æ…ä¹è§‚**
- å¸‚åœºåæš–ï¼Œå¯é€‰æ‹©æ€§å‚ä¸
- é‡ç‚¹å…³æ³¨å¼ºåŠ¿æ¿å—
- æ§åˆ¶ä»“ä½ï¼Œåˆ†æ‰¹å»ºä»“

"""
            else:
                report += """**ğŸ”´ ä¿å®ˆè§‚æœ›**
- å¸‚åœºæƒ…ç»ªåå¼±ï¼Œå»ºè®®æ§åˆ¶ä»“ä½
- é‡ç‚¹å…³æ³¨é˜²å¾¡æ€§æ¿å—
- ç­‰å¾…æ›´å¥½çš„å…¥åœºæ—¶æœº

"""
        
        report += """### âš ï¸ é£é™©æç¤º

- å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…
- æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
- è¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åˆç†é…ç½®èµ„äº§

---

> ğŸ“Š **æŠ¥å‘Šè¯´æ˜**  
> æœ¬æŠ¥å‘ŠåŸºäºé‡åŒ–æ¨¡å‹åˆ†æç”Ÿæˆï¼Œæ•°æ®æ›´æ–°è‡³ {current_time}  
> ğŸ¤– **æŠ€æœ¯æ”¯æŒ**: é‡åŒ–äº¤æ˜“åˆ†æç³»ç»Ÿ"""
        
        return report
    
    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æå¹¶å‘é€æŠ¥å‘Š"""
        try:
            logger.info("å¼€å§‹æ‰§è¡Œ15:00ç»¼åˆåˆ†æ...")
            
            # å‘é€å¼€å§‹é€šçŸ¥
            start_msg = "ğŸ” å¼€å§‹æ‰§è¡Œæ¯æ—¥15:00ç»¼åˆå¸‚åœºåˆ†æ..."
            self.send_message(start_msg)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report = self.format_comprehensive_report()
            
            # å‘é€æŠ¥å‘Š
            success = self.send_markdown(report)
            
            if success:
                logger.info("ç»¼åˆåˆ†ææŠ¥å‘Šå‘é€æˆåŠŸ")
            else:
                # å¦‚æœmarkdownå‘é€å¤±è´¥ï¼Œå°è¯•å‘é€ç®€åŒ–ç‰ˆæœ¬
                simple_msg = "ğŸ“Š æ¯æ—¥ç»¼åˆåˆ†æå®Œæˆï¼Œè¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹ç³»ç»Ÿ"
                self.send_message(simple_msg)
            
        except Exception as e:
            error_msg = f"âŒ ç»¼åˆåˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.send_message(error_msg)
    
    def daily_analysis(self):
        """æ¯æ—¥15:00åˆ†æ"""
        self.run_comprehensive_analysis()
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        logger.info("å¯åŠ¨ç»¼åˆåˆ†æå®šæ—¶ä»»åŠ¡...")
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡ - æ¯æ—¥15:00
        schedule.every().day.at("15:00").do(self.daily_analysis)
        
        logger.info("å®šæ—¶ä»»åŠ¡å·²è®¾ç½®: æ¯æ—¥ 15:00 æ‰§è¡Œç»¼åˆåˆ†æ")
        
        # å‘é€å¯åŠ¨é€šçŸ¥
        start_msg = """ğŸ¤– ç»¼åˆåˆ†ææœºå™¨äººå·²å¯åŠ¨

â° **å®šæ—¶ä»»åŠ¡**: æ¯æ—¥ 15:00

ğŸ“Š **åˆ†æå†…å®¹**:
â€¢ æ¶¨åœæ¦‚å¿µåˆ†æ
â€¢ æŒ‡æ•°RPSåˆ†æ  
â€¢ å¸‚åœºæƒ…ç»ªåˆ†æ
â€¢ æ¿å—åˆ†æ
â€¢ ETFåŠ¨é‡åˆ†æ

ğŸš€ ç³»ç»Ÿå·²å°±ç»ªï¼Œç­‰å¾…å®šæ—¶æ‰§è¡Œ..."""
        
        self.send_markdown(start_msg)
        
        # æŒç»­è¿è¡Œ
        while True:
            try:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
                self.send_message("ğŸ›‘ ç»¼åˆåˆ†ææœºå™¨äººå·²åœæ­¢è¿è¡Œ")
                break
            except Exception as e:
                logger.error(f"è°ƒåº¦å™¨å¼‚å¸¸: {e}")
                time.sleep(60)

def main():
    """ä¸»å‡½æ•°"""
    # ä¼ä¸šå¾®ä¿¡æœºå™¨äººwebhookåœ°å€ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
    import json
    with open('wechat_config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    webhook_url = config['webhook_url']
    
    # åˆ›å»ºæœºå™¨äººå®ä¾‹
    bot = ComprehensiveAnalysisBot(webhook_url)
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡
    bot.start_scheduler()

if __name__ == "__main__":
    main()