"""
æ•°æ®æ¨¡å— - è´Ÿè´£è·å–å’Œå¤„ç†è‚¡ç¥¨æ•°æ®
ä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿äº¤æ˜“æ—¥è¿‡æ»¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ

æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¨¡å¼ï¼š
- åŒæ­¥æ¨¡å¼ï¼šget_stock_data() - å•åªè‚¡ç¥¨
- å¼‚æ­¥æ¨¡å¼ï¼šget_multiple_stocks_data_async() - æ‰¹é‡è‚¡ç¥¨ï¼ˆæ€§èƒ½æå‡3-5å€ï¼‰
"""
import asyncio
import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Callable, Dict, List, Optional, Union

import akshare as ak
import pandas as pd
import streamlit as st

from .constants import (
    ASYNC_BATCH_FETCH_WORKERS,
    CACHE_TTL_LOCAL_DATA,
    CACHE_TTL_ONLINE_DATA,
    DATA_BUFFER_DAYS,
    MAX_DATA_COUNT_DAILY,
    MAX_DATA_COUNT_MONTHLY,
    MAX_DATA_COUNT_WEEKLY,
    MAX_RETURN_ROWS,
    MIN_DATA_COUNT_DAILY,
    MIN_DATA_COUNT_MONTHLY,
    MIN_DATA_COUNT_WEEKLY,
)
from .error_handler import handle_data_error
from .logger_config import get_logger
from .smart_data_manager import cached_realtime_data, cached_stock_data, smart_data_manager
from .utils import format_stock_code

logger = get_logger(__name__)

# æ£€æŸ¥æ•°æ®æºå¯ç”¨æ€§
try:
    # æ˜¾å¼å¯¼å…¥ï¼Œé¿å…å‘½åå†²çª
    # æ³¨æ„ï¼šAshareæ¨¡å—å¯èƒ½å¯¼å‡ºå¤šä¸ªå‡½æ•°ï¼Œè¿™é‡Œåªå¯¼å…¥å¸¸ç”¨çš„
    from .Ashare import (
        get_price,  # Ashareçš„ä¸»è¦æ•°æ®è·å–å‡½æ•°
        get_realtime_quotes_sina,
        get_stock_name,
    )
    has_ashare = True
    logger.info("âœ… Ashareæ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError:
    has_ashare = False
    logger.warning("âŒ Ashareæ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨AKShareä½œä¸ºå¤‡ç”¨æ•°æ®æº")
    # å®šä¹‰å ä½å‡½æ•°ï¼Œé¿å…åç»­è°ƒç”¨é”™è¯¯
    get_price = None
    get_realtime_quotes_sina = None
    get_stock_name = None


@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_ashare(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """
    ä½¿ç”¨Ashareè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '600519' æˆ– '000001'ï¼‰
        start: å¼€å§‹æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        end: ç»“æŸæ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        period_type: æ•°æ®å‘¨æœŸç±»å‹ï¼ˆ'daily'/'weekly'/'monthly'ï¼‰
    
    Returns:
        pd.DataFrame: åŒ…å«OHLCVæ•°æ®çš„DataFrameï¼Œç´¢å¼•ä¸ºæ—¥æœŸ
    
    Raises:
        Exception: æ•°æ®è·å–å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    
    Example:
        >>> df = get_stock_data_ashare('600519', '2023-01-01', '2023-12-31', 'daily')
        >>> print(df.head())
    """
    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        formatted_symbol = format_stock_code(symbol)

        # è½¬æ¢æ—¥æœŸæ ¼å¼
        # è½¬æ¢æ—¥æœŸæ ¼å¼ - Ashareåªæ”¯æŒend_dateå’Œcountå‚æ•°
        end_str = end.strftime("%Y-%m-%d") if hasattr(end, "strftime") else str(end)

        # è®¡ç®—éœ€è¦è·å–çš„æ•°æ®é‡
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)
        days_diff = (end_date - start_date).days

        # æ ¹æ®å‘¨æœŸç±»å‹è®¡ç®—count
        if period_type == "daily":
            count = min(
                max(days_diff + DATA_BUFFER_DAYS, MIN_DATA_COUNT_DAILY), MAX_DATA_COUNT_DAILY
            )
            frequency = "1d"
        elif period_type == "weekly":
            count = min(max(days_diff // 7 + 20, MIN_DATA_COUNT_WEEKLY), MAX_DATA_COUNT_WEEKLY)
            frequency = "1w"
        elif period_type == "monthly":
            count = min(max(days_diff // 30 + 12, MIN_DATA_COUNT_MONTHLY), MAX_DATA_COUNT_MONTHLY)
            frequency = "1M"
        else:
            st.error(f"ä¸æ”¯æŒçš„æ•°æ®å‘¨æœŸ: {period_type}")
            return pd.DataFrame()

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨Ashareè·å– {formatted_symbol} çš„æ•°æ®...")
        logger.debug(f"   ğŸ“… ç»“æŸæ—¥æœŸ: {end_str}")
        logger.debug(f"   ğŸ“Š æ•°æ®ç±»å‹: {period_type}")
        logger.debug(f"   ğŸ“ˆ è·å–æ•°é‡: {count} æ¡")

        # ä½¿ç”¨Ashareè·å–æ•°æ®
        df = get_price(formatted_symbol, end_date=end_str, count=count, frequency=frequency)

        if df.empty:
            logger.warning(f"âŒ Ashareè·å– {formatted_symbol} æ•°æ®ä¸ºç©º")
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å
        df.columns = ["Open", "High", "Low", "Close", "Volume"]

        # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸæ—¶é—´ç±»å‹
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_index()

        # è¿‡æ»¤æ—¥æœŸèŒƒå›´
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)

        if end_date < df.index[0]:
            st.warning(f"è¯·æ±‚çš„ç»“æŸæ—¶é—´ {end_date.date()} æ—©äºæ•°æ®çš„æœ€æ—©æ—¶é—´ {df.index[0].date()}ï¼Œè¿”å›æœ€æ—©æ•°æ®")
            return df.head(min(MAX_RETURN_ROWS, len(df)))
        elif start_date > df.index[-1]:
            st.warning(f"è¯·æ±‚çš„å¼€å§‹æ—¶é—´ {start_date.date()} æ™šäºæ•°æ®çš„æœ€æ–°æ—¶é—´ {df.index[-1].date()}ï¼Œè¿”å›æœ€æ–°æ•°æ®")
            return df.tail(min(MAX_RETURN_ROWS, len(df)))
        else:
            mask = (df.index >= start_date) & (df.index <= end_date)
            df_filtered = df.loc[mask]

            if df_filtered.empty:
                return df.head(min(MAX_RETURN_ROWS, len(df)))

        logger.info(f"âœ… Ashareæ•°æ®è·å–æˆåŠŸ!")
        logger.debug(f"   ğŸ“Š æ•°æ®æ¡æ•°: {len(df_filtered)}")
        logger.debug(f"   ğŸ“… æ—¶é—´èŒƒå›´: {df_filtered.index[0]} åˆ° {df_filtered.index[-1]}")
        logger.debug(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {df_filtered['Close'].iloc[-1]:.2f}")

        return df_filtered

    except Exception as e:
        logger.error(f"Ashareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"Ashareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@handle_data_error
@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_ak(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä½¿ç”¨AKShareè·å–è‚¡ç¥¨æ•°æ®"""
    try:
        # æ¸…ç†è‚¡ç¥¨ä»£ç ï¼Œç§»é™¤å‰ç¼€å’Œåç¼€
        # AKShareéœ€è¦çº¯æ•°å­—ä»£ç ï¼Œå¦‚ "600519"
        formatted_symbol = symbol.strip()

        # ç§»é™¤ "sh" æˆ– "sz" å‰ç¼€
        if formatted_symbol.lower().startswith(("sh", "sz")):
            formatted_symbol = formatted_symbol[2:]

        # ç§»é™¤ ".SH" æˆ– ".SZ" åç¼€
        if "." in formatted_symbol:
            formatted_symbol = formatted_symbol.split(".")[0]

        # ç¡®ä¿æ˜¯çº¯æ•°å­—
        formatted_symbol = "".join(filter(str.isdigit, formatted_symbol))

        if not formatted_symbol:
            st.error("âŒ æ— æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return pd.DataFrame()

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨AKShareè·å– {formatted_symbol} çš„æ•°æ®...")

        # æ ¹æ®å‘¨æœŸç±»å‹è·å–æ•°æ®
        if period_type in ["daily", "weekly", "monthly"]:
            # è½¬æ¢å‘¨æœŸå‚æ•°
            period_map = {"daily": "daily", "weekly": "weekly", "monthly": "monthly"}
            period = period_map[period_type]

            # æ ¼å¼åŒ–æ—¥æœŸ
            start_date = (
                start.strftime("%Y%m%d")
                if hasattr(start, "strftime")
                else str(start).replace("-", "")
            )
            end_date = (
                end.strftime("%Y%m%d") if hasattr(end, "strftime") else str(end).replace("-", "")
            )

            # è·å–è‚¡ç¥¨å†å²æ•°æ®
            df = ak.stock_zh_a_hist(
                symbol=formatted_symbol,
                period=period,
                start_date=start_date,
                end_date=end_date,
                adjust="qfq",
            )

            if df.empty:
                return pd.DataFrame()

            # å¤„ç†æ—¥æœŸå’Œç´¢å¼•
            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
            df = df.sort_values("æ—¥æœŸ").set_index("æ—¥æœŸ")

            # æ ‡å‡†åŒ–åˆ—å
            if "å¼€ç›˜" in df.columns:
                df = df.rename(
                    columns={
                        "å¼€ç›˜": "Open",
                        "æ”¶ç›˜": "Close",
                        "æœ€é«˜": "High",
                        "æœ€ä½": "Low",
                        "æˆäº¤é‡": "Volume",
                    }
                )

            logger.info(f"âœ… AKShareæ•°æ®è·å–æˆåŠŸ!")
            logger.debug(f"   ğŸ“Š æ•°æ®æ¡æ•°: {len(df)}")
            if not df.empty:
                logger.debug(f"   ğŸ“… æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
                logger.debug(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {df['Close'].iloc[-1]:.2f}")

            return df

    except Exception as e:
        logger.error(f"AKShareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"AKShareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


# å°è¯•å¯¼å…¥Tushareç›¸å…³æ¨¡å—
try:
    import os
    import sys

    # æ·»åŠ aitrader_coreåˆ°è·¯å¾„
    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "aitrader_core"))
    from datafeed.tushare_loader import get_stock_data as tushare_get_stock_data

    has_tushare = True
except ImportError:
    has_tushare = False
    logger.warning("âš ï¸ Tushareæ¨¡å—æœªæ‰¾åˆ°")

# å°è¯•å¯¼å…¥CSVæ•°æ®åŠ è½½å™¨
try:
    from datafeed.csv_dataloader import CsvDataLoader

    has_csv = True
except ImportError:
    has_csv = False
    logger.warning("âš ï¸ CSVæ•°æ®åŠ è½½å™¨æœªæ‰¾åˆ°")


@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_tushare(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä½¿ç”¨Tushareè·å–è‚¡ç¥¨æ•°æ®"""
    if not has_tushare:
        st.warning("Tushareæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥aitrader_core/datafeed/tushare_loader.py")
        return pd.DataFrame()

    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä¸ºTushareæ ¼å¼ (å¦‚: 600519.SH)
        if "." not in symbol:
            if symbol.startswith("6"):
                symbol = f"{symbol}.SH"
            elif symbol.startswith(("0", "3")):
                symbol = f"{symbol}.SZ"

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨Tushareè·å– {symbol} çš„æ•°æ®...")

        # è°ƒç”¨tushare_loader (æ³¨æ„ï¼štushare_loaderæ²¡æœ‰freqå‚æ•°ï¼Œåªæ”¯æŒæ—¥çº¿)
        df = tushare_get_stock_data(
            symbol=symbol,
            start_date=start.strftime("%Y%m%d")
            if hasattr(start, "strftime")
            else str(start).replace("-", ""),
            end_date=end.strftime("%Y%m%d")
            if hasattr(end, "strftime")
            else str(end).replace("-", ""),
        )

        if df is None or df.empty:
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å (tushareè¿”å›å°å†™åˆ—å)
        column_mapping = {
            "date": "Date",
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
        }

        df = df.rename(columns=column_mapping)

        # ç¡®ä¿Dateåˆ—æ˜¯datetimeç±»å‹
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date")

        # åªä¿ç•™éœ€è¦çš„åˆ—
        required_columns = ["Open", "High", "Low", "Close", "Volume"]
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_index()

        logger.info(f"âœ… Tushareæ•°æ®è·å–æˆåŠŸ! æ•°æ®æ¡æ•°: {len(df)}")
        return df

    except Exception as e:
        logger.error(f"Tushareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"Tushareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@handle_data_error
@st.cache_data(ttl=CACHE_TTL_LOCAL_DATA, show_spinner=False)
def get_stock_data_csv(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä»æœ¬åœ°CSVæ–‡ä»¶è·å–è‚¡ç¥¨æ•°æ®"""
    if not has_csv:
        st.warning("CSVæ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")
        return pd.DataFrame()

    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        if "." not in symbol:
            if symbol.startswith("6"):
                symbol = f"{symbol}.SH"
            elif symbol.startswith(("0", "3")):
                symbol = f"{symbol}.SZ"

        logger.info(f"ğŸ”„ æ­£åœ¨ä»æœ¬åœ°CSVè·å– {symbol} çš„æ•°æ®...")

        # é¦–å…ˆå°è¯•ç”¨æˆ·ç›®å½•ä¸‹çš„stock_dataæ–‡ä»¶å¤¹
        user_stock_data_dir = os.path.expanduser("~/stock_data")

        # åˆ›å»ºCSVåŠ è½½å™¨å®ä¾‹ (CsvDataLoaderä¸æ¥å—data_dirå‚æ•°)
        csv_loader = CsvDataLoader()

        # æ ¹æ®è·¯å¾„å†³å®šä½¿ç”¨å“ªä¸ªç›®å½•
        if os.path.exists(user_stock_data_dir):
            csv_path = user_stock_data_dir
            logger.debug(f"ğŸ“ ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {user_stock_data_dir}")
        else:
            # å›é€€åˆ°é»˜è®¤è·¯å¾„ (ä½¿ç”¨'quotes'ä¼šè‡ªåŠ¨ä½¿ç”¨DATA_DIR/quotes)
            csv_path = "quotes"
            logger.debug(f"ğŸ“ ä½¿ç”¨é»˜è®¤æ•°æ®ç›®å½•")

        # è¯»å–CSVæ•°æ® (ä¼ å…¥pathå‚æ•°)
        df = csv_loader._read_csv(symbol, path=csv_path)

        if df is None or df.empty:
            st.warning(f"æœ¬åœ°CSVæœªæ‰¾åˆ° {symbol} çš„æ•°æ®æ–‡ä»¶")
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€ŒAIæ•°æ®ç®¡ç†ã€ä¸­æ›´æ–°è‚¡ç¥¨æ•°æ®")
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å (CSVé€šå¸¸è¿”å›å°å†™åˆ—å)
        column_mapping = {
            "date": "Date",
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
        }

        df = df.rename(columns=column_mapping)

        # ç¡®ä¿Dateåˆ—æ˜¯datetimeç±»å‹å¹¶è®¾ç½®ä¸ºç´¢å¼•
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date")

        # åªä¿ç•™éœ€è¦çš„åˆ—
        required_columns = ["Open", "High", "Low", "Close", "Volume"]
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]

        # æŒ‰æ—¥æœŸè¿‡æ»¤
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)
        df = df[(df.index >= start_date) & (df.index <= end_date)]

        if df.empty:
            st.warning(f"âš ï¸ åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…({start} è‡³ {end})æœªæ‰¾åˆ°æ•°æ®")
            return pd.DataFrame()

        logger.info(f"âœ… CSVæ•°æ®åŠ è½½æˆåŠŸ! æ•°æ®æ¡æ•°: {len(df)}")
        return df

    except Exception as e:
        logger.error(f"CSVæ•°æ®åŠ è½½å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"CSVæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()


def get_stock_data(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
    data_source: str = "Ashare",
) -> pd.DataFrame:
    """
    è·å–è‚¡ç¥¨æ•°æ®çš„ä¸»å‡½æ•°ï¼Œæ ¹æ®æ•°æ®æºé€‰æ‹©ä¸åŒçš„è·å–æ–¹æ³•
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '600519' æˆ– '000001'ï¼‰
        start: å¼€å§‹æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        end: ç»“æŸæ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        period_type: æ•°æ®å‘¨æœŸç±»å‹ï¼ˆ'daily'/'weekly'/'monthly'ï¼‰
        data_source: æ•°æ®æºé€‰æ‹©ï¼ˆ'Ashare'/'AKShare'/'Tushare'/'æœ¬åœ°CSV'ï¼‰
    
    Returns:
        pd.DataFrame: åŒ…å«OHLCVæ•°æ®çš„DataFrameï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œå·²è¿‡æ»¤éäº¤æ˜“æ—¥
    
    Note:
        - è‡ªåŠ¨åº”ç”¨äº¤æ˜“æ—¥è¿‡æ»¤ï¼ˆæ’é™¤å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
        - æ”¯æŒå¤šç§æ•°æ®æºè‡ªåŠ¨å›é€€
        - æ•°æ®è‡ªåŠ¨ç¼“å­˜ï¼ˆåœ¨çº¿æ•°æ®1å°æ—¶ï¼Œæœ¬åœ°æ•°æ®2å°æ—¶ï¼‰
    
    Example:
        >>> df = get_stock_data('600519', '2023-01-01', '2023-12-31', 'daily', 'Ashare')
        >>> print(f"è·å–åˆ° {len(df)} æ¡äº¤æ˜“æ—¥æ•°æ®")
    """
    try:
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if not isinstance(start, (str, pd.Timestamp, datetime.datetime)):
            start = pd.to_datetime(start, format="%Y%m%d")
        if not isinstance(end, (str, pd.Timestamp, datetime.datetime)):
            end = pd.to_datetime(end, format="%Y%m%d")

        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ•°æ®æºè·å–æ•°æ®
        if data_source == "Ashare" and has_ashare:
            df = get_stock_data_ashare(symbol, start, end, period_type)
        elif data_source == "Ashare" and not has_ashare:
            st.warning("ğŸ’¡ æœªæ£€æµ‹åˆ°Ashareæ¨¡å—ï¼Œä½¿ç”¨AKShareæ•°æ®æº")
            df = get_stock_data_ak(symbol, start, end, period_type)
        elif data_source == "Tushare":
            if has_tushare:
                df = get_stock_data_tushare(symbol, start, end, period_type)
            else:
                st.warning("ğŸ’¡ Tushareæ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                df = get_stock_data_ak(symbol, start, end, period_type)
        elif data_source == "æœ¬åœ°CSV":
            if has_csv:
                df = get_stock_data_csv(symbol, start, end, period_type)
            else:
                st.warning("ğŸ’¡ CSVæ•°æ®æºä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                df = get_stock_data_ak(symbol, start, end, period_type)
        else:
            # ä½¿ç”¨AKShareæ•°æ®æº
            df = get_stock_data_ak(symbol, start, end, period_type)

        # ğŸ”§ ç»Ÿä¸€åº”ç”¨äº¤æ˜“æ—¥è¿‡æ»¤ï¼Œç¡®ä¿Kçº¿è¿ç»­æ˜¾ç¤º
        if not df.empty and period_type in ["daily", "weekly", "monthly"]:
            from .trading_calendar import filter_trading_days

            original_count = len(df)
            df = filter_trading_days(df)
            filtered_count = len(df)

            if filtered_count < original_count:
                st.info(f"ğŸ“… äº¤æ˜“æ—¥è¿‡æ»¤: {original_count} â†’ {filtered_count} æ¡æ•°æ®")
                st.success(f"âœ… å·²è¿‡æ»¤æ‰ {original_count - filtered_count} ä¸ªéäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰")

        return df

    except Exception as e:
        st.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()


# å…¶ä»–è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜
def get_realtime_price(symbol: str) -> Optional[float]:
    """è·å–å®æ—¶è‚¡ä»·"""
    try:
        # ä½¿ç”¨ç¼“å­˜çš„å®æ—¶æ•°æ®
        return cached_realtime_data(symbol)
    except Exception as e:
        st.error(f"è·å–å®æ—¶ä»·æ ¼å¤±è´¥: {str(e)}")
        return None


def get_stock_info(symbol: str) -> Optional[pd.DataFrame]:
    """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    try:
        formatted_symbol = format_stock_code(symbol)

        if has_ashare:
            # ä½¿ç”¨Ashareè·å–è‚¡ç¥¨ä¿¡æ¯
            try:
                from .Ashare import get_security_info

                info = get_security_info(formatted_symbol)
                return info
            except (ImportError, AttributeError):
                logger.warning("Ashareçš„get_security_infoå‡½æ•°ä¸å¯ç”¨")
                # å›é€€åˆ°AKShare
                info = ak.stock_individual_info_em(symbol=formatted_symbol)
                return info
        else:
            # ä½¿ç”¨AKShareè·å–è‚¡ç¥¨ä¿¡æ¯
            info = ak.stock_individual_info_em(symbol=formatted_symbol)
            return info

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None


# ========== å¼‚æ­¥æ‰¹é‡æ•°æ®è·å–ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰ ==========


def _fetch_single_stock_sync(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
    data_source: str,
) -> Dict[str, Any]:
    """
    åŒæ­¥è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆç”¨äºå¼‚æ­¥å¹¶å‘ï¼‰

    Returns:
        dict: {'symbol': str, 'status': 'success'|'error', 'data': pd.DataFrame|None, 'error': str|None}
    """
    try:
        df = get_stock_data(symbol, start, end, period_type, data_source)
        if df is not None and not df.empty:
            return {"symbol": symbol, "status": "success", "data": df, "error": None}
        else:
            return {"symbol": symbol, "status": "error", "data": None, "error": "æ•°æ®ä¸ºç©º"}
    except Exception as e:
        logger.error(f"è·å– {symbol} æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
        return {"symbol": symbol, "status": "error", "data": None, "error": str(e)}


async def get_multiple_stocks_data_async(
    symbols: List[str],
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str = "daily",
    data_source: str = "Ashare",
    max_workers: int = ASYNC_BATCH_FETCH_WORKERS,
    progress_callback: Optional[Callable] = None,
) -> Dict[str, pd.DataFrame]:
    """
    å¼‚æ­¥æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        period_type: æ•°æ®å‘¨æœŸç±»å‹
        data_source: æ•°æ®æº
        max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼Œé¿å…APIé™æµï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total, symbol)

    Returns:
        dict: {symbol: DataFrame} æˆåŠŸè·å–çš„æ•°æ®å­—å…¸

    Example:
        symbols = ['600519', '000001', '000002']
        data_dict = await get_multiple_stocks_data_async(
            symbols, '2023-01-01', '2023-12-31'
        )
        # è¿”å›: {'600519': DataFrame, '000001': DataFrame, ...}
    """
    logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ‰¹é‡è·å– {len(symbols)} åªè‚¡ç¥¨æ•°æ®ï¼ˆå¹¶å‘æ•°: {max_workers}ï¼‰")

    loop = asyncio.get_event_loop()
    results = {}
    completed = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:

        async def fetch_single(symbol: str):
            return await loop.run_in_executor(
                executor, _fetch_single_stock_sync, symbol, start, end, period_type, data_source
            )

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [fetch_single(symbol) for symbol in symbols]
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(task_results):
            symbol = symbols[i]
            completed += 1

            if isinstance(result, Exception):
                logger.error(f"è·å– {symbol} æ•°æ®å¼‚å¸¸: {result}", exc_info=True)
                if progress_callback:
                    progress_callback(completed, len(symbols), symbol)
                continue

            if isinstance(result, dict):
                if result["status"] == "success" and result["data"] is not None:
                    results[symbol] = result["data"]
                    logger.debug(f"âœ… {symbol} æ•°æ®è·å–æˆåŠŸ: {len(result['data'])} æ¡")
                else:
                    logger.warning(f"âš ï¸ {symbol} æ•°æ®è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

                if progress_callback:
                    progress_callback(completed, len(symbols), symbol)

    logger.info(f"âœ… å¼‚æ­¥æ‰¹é‡è·å–å®Œæˆ: æˆåŠŸ {len(results)}/{len(symbols)} åª")
    return results


def get_multiple_stocks_data(
    symbols: List[str],
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str = "daily",
    data_source: str = "Ashare",
    use_async: bool = True,
    max_workers: int = 5,
) -> Dict[str, pd.DataFrame]:
    """
    æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®ï¼ˆåŒæ­¥æ¥å£ï¼Œå†…éƒ¨å¯é€‰æ‹©å¼‚æ­¥ï¼‰

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        period_type: æ•°æ®å‘¨æœŸç±»å‹
        data_source: æ•°æ®æº
        use_async: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼Œæ€§èƒ½æå‡3-5å€ï¼‰
        max_workers: å¼‚æ­¥æ¨¡å¼çš„æœ€å¤§å¹¶å‘æ•°

    Returns:
        dict: {symbol: DataFrame} æˆåŠŸè·å–çš„æ•°æ®å­—å…¸
    """
    if use_async:
        # å¼‚æ­¥æ¨¡å¼
        try:
            return asyncio.run(
                get_multiple_stocks_data_async(
                    symbols, start, end, period_type, data_source, max_workers
                )
            )
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ‰¹é‡è·å–å¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼: {e}")
            # å›é€€åˆ°åŒæ­¥æ¨¡å¼
            use_async = False

    if not use_async:
        # åŒæ­¥æ¨¡å¼
        results = {}
        for i, symbol in enumerate(symbols):
            try:
                df = get_stock_data(symbol, start, end, period_type, data_source)
                if df is not None and not df.empty:
                    results[symbol] = df
                    logger.debug(f"âœ… {symbol} æ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡")
            except Exception as e:
                logger.warning(f"âš ï¸ {symbol} æ•°æ®è·å–å¤±è´¥: {str(e)}")

        return results
