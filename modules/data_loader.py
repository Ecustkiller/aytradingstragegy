"""
æ•°æ®æ¨¡å— - è´Ÿè´£è·å–å’Œå¤„ç†è‚¡ç¥¨æ•°æ®
ä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿äº¤æ˜“æ—¥è¿‡æ»¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ

æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥ä¸¤ç§æ¨¡å¼ï¼š
- åŒæ­¥æ¨¡å¼ï¼šget_stock_data() - å•åªè‚¡ç¥¨
- å¼‚æ­¥æ¨¡å¼ï¼šget_multiple_stocks_data_async() - æ‰¹é‡è‚¡ç¥¨ï¼ˆæ€§èƒ½æå‡3-5å€ï¼‰
"""
import asyncio
import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Callable, Dict, List, Optional, Union

import akshare as ak
import pandas as pd
import streamlit as st

from .constants import (
    ASYNC_BATCH_FETCH_WORKERS,
    CACHE_TTL_LOCAL_DATA,
    CACHE_TTL_ONLINE_DATA,
    DATA_BUFFER_DAYS,
    MAX_DATA_COUNT_DAILY,
    MAX_DATA_COUNT_MONTHLY,
    MAX_DATA_COUNT_WEEKLY,
    MAX_RETURN_ROWS,
    MIN_DATA_COUNT_DAILY,
    MIN_DATA_COUNT_MONTHLY,
    MIN_DATA_COUNT_WEEKLY,
)
from .error_handler import handle_data_error
from .logger_config import get_logger
from .smart_data_manager import cached_realtime_data, cached_stock_data, smart_data_manager
from .utils import format_stock_code

# å¯¼å…¥é‡è¯•æœºåˆ¶
try:
    from tenacity import (
        retry,
        stop_after_attempt,
        wait_exponential,
        retry_if_exception_type,
        RetryError
    )
    HAS_TENACITY = True
except ImportError:
    HAS_TENACITY = False
    logger.warning("tenacity æœªå®‰è£…ï¼Œé‡è¯•åŠŸèƒ½å°†ä¸å¯ç”¨")

logger = get_logger(__name__)


# ========== æ•°æ®éªŒè¯å‡½æ•° ==========

def validate_stock_code(symbol: str) -> tuple[bool, str]:
    """
    éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        (is_valid, error_message): éªŒè¯ç»“æœå’Œé”™è¯¯ä¿¡æ¯
    """
    if not symbol:
        return False, "è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º"
    
    # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    symbol = str(symbol).strip()
    
    # æå–çº¯æ•°å­—éƒ¨åˆ†
    if '.' in symbol:
        code_part = symbol.split('.')[0]
    elif symbol.startswith(('sh', 'sz', 'bj', 'nq')):
        code_part = symbol[2:]
    else:
        code_part = symbol
    
    # æ£€æŸ¥æ˜¯å¦ä¸º6ä½æ•°å­—
    if not code_part.isdigit():
        return False, f"è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯ï¼š'{symbol}' åº”åŒ…å«6ä½æ•°å­—"
    
    if len(code_part) != 6:
        return False, f"è‚¡ç¥¨ä»£ç é•¿åº¦é”™è¯¯ï¼š'{symbol}' åº”ä¸º6ä½æ•°å­—"
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆAè‚¡ã€åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ç­‰ï¼‰
    code_int = int(code_part)
    valid_ranges = [
        (600000, 605999),  # ä¸Šæµ·Aè‚¡
        (0, 2999),  # æ·±åœ³Aè‚¡ (000000-002999)
        (300000, 301999),  # åˆ›ä¸šæ¿
        (688000, 688999),  # ç§‘åˆ›æ¿
        (430000, 439999),  # æ–°ä¸‰æ¿
        (830000, 839999),  # æ–°ä¸‰æ¿
    ]
    
    # æ£€æŸ¥æ·±åœ³Aè‚¡ï¼ˆ000000-002999ï¼‰éœ€è¦ç‰¹æ®Šå¤„ç†
    is_valid = any(start <= code_int <= end for start, end in valid_ranges)
    # æ·±åœ³Aè‚¡ç‰¹æ®Šæ£€æŸ¥ï¼š000000-002999
    if not is_valid and 0 <= code_int <= 2999:
        is_valid = True
    
    if not is_valid:
        return False, f"è‚¡ç¥¨ä»£ç  '{symbol}' ä¸åœ¨æœ‰æ•ˆçš„Aè‚¡ä»£ç èŒƒå›´å†…"
    
    return True, ""


def validate_date_range(
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp]
) -> tuple[bool, str]:
    """
    éªŒè¯æ—¥æœŸèŒƒå›´
    
    Args:
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        
    Returns:
        (is_valid, error_message): éªŒè¯ç»“æœå’Œé”™è¯¯ä¿¡æ¯
    """
    try:
        # è½¬æ¢ä¸ºdatetime
        if isinstance(start, str):
            start = pd.to_datetime(start)
        if isinstance(end, str):
            end = pd.to_datetime(end)
        
        # æ£€æŸ¥æ—¥æœŸé¡ºåº
        if end < start:
            return False, f"ç»“æŸæ—¥æœŸï¼ˆ{end.strftime('%Y-%m-%d')}ï¼‰ä¸èƒ½æ—©äºå¼€å§‹æ—¥æœŸï¼ˆ{start.strftime('%Y-%m-%d')}ï¼‰"
        
        # æ£€æŸ¥æœªæ¥æ—¥æœŸ
        now = datetime.datetime.now()
        if end > now:
            return False, f"ç»“æŸæ—¥æœŸï¼ˆ{end.strftime('%Y-%m-%d')}ï¼‰ä¸èƒ½æ˜¯æœªæ¥æ—¥æœŸ"
        
        # æ£€æŸ¥æ—¥æœŸèŒƒå›´ï¼ˆä¸èƒ½è¶…è¿‡5å¹´ï¼‰
        days_diff = (end - start).days
        if days_diff > 365 * 5:
            return False, f"æ—¥æœŸèŒƒå›´ä¸èƒ½è¶…è¿‡5å¹´ï¼ˆå½“å‰ï¼š{days_diff}å¤©ï¼‰"
        
        # æ£€æŸ¥å¼€å§‹æ—¥æœŸä¸èƒ½å¤ªæ—©ï¼ˆAè‚¡æ•°æ®é€šå¸¸ä»1990å¹´å¼€å§‹ï¼‰
        if start < pd.to_datetime('1990-01-01'):
            return False, f"å¼€å§‹æ—¥æœŸï¼ˆ{start.strftime('%Y-%m-%d')}ï¼‰ä¸èƒ½æ—©äº1990å¹´ï¼ˆAè‚¡å¸‚åœºèµ·å§‹æ—¶é—´ï¼‰"
        
        return True, ""
        
    except Exception as e:
        return False, f"æ—¥æœŸæ ¼å¼é”™è¯¯ï¼š{str(e)}"


def format_user_friendly_error(
    error: Exception,
    symbol: str,
    data_source: str,
    context: str = ""
) -> str:
    """
    æ ¼å¼åŒ–ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
    
    Args:
        error: å¼‚å¸¸å¯¹è±¡
        data_source: æ•°æ®æºåç§°
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
    Returns:
        æ ¼å¼åŒ–çš„é”™è¯¯ä¿¡æ¯
    """
    error_type = type(error).__name__
    error_msg = str(error)
    
    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„æç¤º
    if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
        return f"â±ï¸ æ•°æ®è·å–è¶…æ—¶\n\n**åŸå› ï¼š** ç½‘ç»œè¿æ¥è¾ƒæ…¢æˆ–æ•°æ®æºå“åº”è¶…æ—¶\n**è‚¡ç¥¨ï¼š** {symbol}\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- æ£€æŸ¥ç½‘ç»œè¿æ¥\n- ç¨åé‡è¯•\n- å°è¯•åˆ‡æ¢æ•°æ®æº"
    
    elif "connection" in error_msg.lower() or "ç½‘ç»œ" in error_msg:
        return f"ğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥\n\n**åŸå› ï¼š** æ— æ³•è¿æ¥åˆ°æ•°æ®æºæœåŠ¡å™¨\n**è‚¡ç¥¨ï¼š** {symbol}\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- æ£€æŸ¥ç½‘ç»œè¿æ¥\n- æ£€æŸ¥é˜²ç«å¢™è®¾ç½®\n- å°è¯•åˆ‡æ¢æ•°æ®æº"
    
    elif "not found" in error_msg.lower() or "ä¸å­˜åœ¨" in error_msg or "404" in error_msg:
        return f"âŒ è‚¡ç¥¨ä»£ç ä¸å­˜åœ¨\n\n**åŸå› ï¼š** æœªæ‰¾åˆ°è‚¡ç¥¨ '{symbol}' çš„æ•°æ®\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®\n- ç¡®è®¤è‚¡ç¥¨æ˜¯å¦å·²é€€å¸‚\n- å°è¯•å…¶ä»–è‚¡ç¥¨ä»£ç "
    
    elif "rate limit" in error_msg.lower() or "é¢‘ç‡" in error_msg or "é™åˆ¶" in error_msg:
        return f"â¸ï¸ è¯·æ±‚è¿‡äºé¢‘ç¹\n\n**åŸå› ï¼š** æ•°æ®æºAPIè¯·æ±‚é¢‘ç‡é™åˆ¶\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- ç­‰å¾…30ç§’åé‡è¯•\n- å°è¯•åˆ‡æ¢æ•°æ®æº\n- å‡å°‘è¯·æ±‚é¢‘ç‡"
    
    elif "permission" in error_msg.lower() or "æƒé™" in error_msg or "401" in error_msg or "403" in error_msg:
        return f"ğŸ”’ æƒé™ä¸è¶³\n\n**åŸå› ï¼š** æ•°æ®æºè®¿é—®æƒé™å—é™\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- æ£€æŸ¥APIå¯†é’¥é…ç½®\n- ç¡®è®¤è´¦æˆ·æƒé™\n- è”ç³»æ•°æ®æºæä¾›å•†"
    
    else:
        # é€šç”¨é”™è¯¯ä¿¡æ¯
        return f"âŒ æ•°æ®è·å–å¤±è´¥\n\n**é”™è¯¯ç±»å‹ï¼š** {error_type}\n**é”™è¯¯ä¿¡æ¯ï¼š** {error_msg}\n**è‚¡ç¥¨ï¼š** {symbol}\n**æ•°æ®æºï¼š** {data_source}\n\nğŸ’¡ **å»ºè®®ï¼š**\n- æ£€æŸ¥è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´\n- å°è¯•åˆ‡æ¢æ•°æ®æº\n- ç¨åé‡è¯•\n- å¦‚é—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ"


def check_data_quality(df: pd.DataFrame, symbol: str) -> Dict[str, Any]:
    """
    æ£€æŸ¥æ•°æ®è´¨é‡
    
    Args:
        df: è‚¡ç¥¨æ•°æ®DataFrame
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        dict: æ•°æ®è´¨é‡ä¿¡æ¯
    """
    quality = {
        'is_latest': False,
        'is_complete': False,
        'has_delay': False,
        'missing_days': 0,
        'warnings': []
    }
    
    if df.empty:
        quality['warnings'].append("æ•°æ®ä¸ºç©º")
        return quality
    
    try:
        from .trading_calendar import get_latest_trading_day
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ€æ–°äº¤æ˜“æ—¥
        latest_trading_day = get_latest_trading_day()
        latest_trading_date = pd.to_datetime(latest_trading_day)
        
        if latest_trading_date in df.index:
            quality['is_latest'] = True
        else:
            quality['has_delay'] = True
            days_delay = (pd.to_datetime('today') - df.index[-1]).days
            if days_delay > 3:
                quality['warnings'].append(f"æ•°æ®å¯èƒ½ä¸æ˜¯æœ€æ–°çš„ï¼Œæœ€æ–°æ•°æ®æ—¥æœŸï¼š{df.index[-1].strftime('%Y-%m-%d')}ï¼Œå»¶è¿Ÿçº¦ {days_delay} å¤©")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„äº¤æ˜“æ—¥ï¼‰
        if len(df) > 1:
            # è®¡ç®—é¢„æœŸäº¤æ˜“æ—¥æ•°ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
            date_range = (df.index[-1] - df.index[0]).days
            # å‡è®¾äº¤æ˜“æ—¥å æ¯”çº¦65%ï¼ˆæ’é™¤å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
            expected_trading_days = int(date_range * 0.65)
            actual_days = len(df)
            
            if actual_days < expected_trading_days * 0.9:
                quality['is_complete'] = False
                quality['missing_days'] = expected_trading_days - actual_days
                if quality['missing_days'] > 10:
                    quality['warnings'].append(f"æ•°æ®å¯èƒ½ä¸å®Œæ•´ï¼Œé¢„æœŸçº¦ {expected_trading_days} ä¸ªäº¤æ˜“æ—¥ï¼Œå®é™… {actual_days} ä¸ªï¼Œç¼ºå¤±çº¦ {quality['missing_days']} å¤©")
        
        # æ£€æŸ¥æ•°æ®å¼‚å¸¸å€¼
        if 'Close' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çš„ä»·æ ¼æ³¢åŠ¨ï¼ˆå•æ—¥æ¶¨è·Œå¹…è¶…è¿‡20%ï¼‰
            if len(df) > 1:
                pct_change = df['Close'].pct_change().abs()
                extreme_changes = pct_change[pct_change > 0.2]
                if len(extreme_changes) > 0:
                    quality['warnings'].append(f"å‘ç° {len(extreme_changes)} ä¸ªå¼‚å¸¸ä»·æ ¼æ³¢åŠ¨ï¼ˆå•æ—¥æ¶¨è·Œå¹…>20%ï¼‰ï¼Œè¯·æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§")
        
        quality['is_complete'] = True if not quality['warnings'] else False
        
    except Exception as e:
        logger.warning(f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        quality['warnings'].append("æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥")
    
    return quality


def _get_stock_data_with_retry(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
    data_source: str,
) -> pd.DataFrame:
    """
    å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®è·å–å‡½æ•°
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        period_type: æ•°æ®å‘¨æœŸç±»å‹
        data_source: æ•°æ®æº
        
    Returns:
        pd.DataFrame: è‚¡ç¥¨æ•°æ®
    """
    # å®šä¹‰é‡è¯•è£…é¥°å™¨ï¼ˆä»…å¯¹ç½‘ç»œé”™è¯¯é‡è¯•ï¼‰
    if HAS_TENACITY:
        @retry(
            stop=stop_after_attempt(3),
            wait=wait_exponential(multiplier=1, min=2, max=10),
            retry=retry_if_exception_type((ConnectionError, TimeoutError, OSError))
        )
        def _fetch_with_retry():
            if data_source == "Ashare" and has_ashare:
                return get_stock_data_ashare(symbol, start, end, period_type)
            elif data_source == "Ashare" and not has_ashare:
                st.warning("ğŸ’¡ æœªæ£€æµ‹åˆ°Ashareæ¨¡å—ï¼Œä½¿ç”¨AKShareæ•°æ®æº")
                return get_stock_data_ak(symbol, start, end, period_type)
            elif data_source == "Tushare":
                if has_tushare:
                    return get_stock_data_tushare(symbol, start, end, period_type)
                else:
                    st.warning("ğŸ’¡ Tushareæ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                    return get_stock_data_ak(symbol, start, end, period_type)
            elif data_source == "æœ¬åœ°CSV":
                if has_csv:
                    return get_stock_data_csv(symbol, start, end, period_type)
                else:
                    st.warning("ğŸ’¡ CSVæ•°æ®æºä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                    return get_stock_data_ak(symbol, start, end, period_type)
            else:
                # ä½¿ç”¨AKShareæ•°æ®æº
                return get_stock_data_ak(symbol, start, end, period_type)
        
        try:
            return _fetch_with_retry()
        except RetryError as e:
            # é‡è¯•å¤±è´¥åï¼Œå°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
            logger.warning(f"æ•°æ®æº {data_source} é‡è¯•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº: {e}")
            if data_source != "AKShare":
                st.warning(f"ğŸ’¡ {data_source} æ•°æ®æºå¤±è´¥ï¼Œåˆ‡æ¢åˆ°AKShare")
                return get_stock_data_ak(symbol, start, end, period_type)
            else:
                raise
    else:
        # å¦‚æœæ²¡æœ‰tenacityï¼Œç›´æ¥è°ƒç”¨ï¼ˆæ— é‡è¯•ï¼‰
        if data_source == "Ashare" and has_ashare:
            return get_stock_data_ashare(symbol, start, end, period_type)
        elif data_source == "Ashare" and not has_ashare:
            st.warning("ğŸ’¡ æœªæ£€æµ‹åˆ°Ashareæ¨¡å—ï¼Œä½¿ç”¨AKShareæ•°æ®æº")
            return get_stock_data_ak(symbol, start, end, period_type)
        elif data_source == "Tushare":
            if has_tushare:
                return get_stock_data_tushare(symbol, start, end, period_type)
            else:
                st.warning("ğŸ’¡ Tushareæ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                return get_stock_data_ak(symbol, start, end, period_type)
        elif data_source == "æœ¬åœ°CSV":
            if has_csv:
                return get_stock_data_csv(symbol, start, end, period_type)
            else:
                st.warning("ğŸ’¡ CSVæ•°æ®æºä¸å¯ç”¨ï¼Œå›é€€åˆ°AKShare")
                return get_stock_data_ak(symbol, start, end, period_type)
        else:
            # ä½¿ç”¨AKShareæ•°æ®æº
            return get_stock_data_ak(symbol, start, end, period_type)


# æ£€æŸ¥æ•°æ®æºå¯ç”¨æ€§
try:
    # æ˜¾å¼å¯¼å…¥ï¼Œé¿å…å‘½åå†²çª
    # æ³¨æ„ï¼šAshareæ¨¡å—å¯èƒ½å¯¼å‡ºå¤šä¸ªå‡½æ•°ï¼Œè¿™é‡Œåªå¯¼å…¥å¸¸ç”¨çš„
    from .Ashare import (
        get_price,  # Ashareçš„ä¸»è¦æ•°æ®è·å–å‡½æ•°
        get_realtime_quotes_sina,
        get_stock_name,
    )
    has_ashare = True
    logger.info("âœ… Ashareæ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError:
    has_ashare = False
    logger.warning("âŒ Ashareæ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨AKShareä½œä¸ºå¤‡ç”¨æ•°æ®æº")
    # å®šä¹‰å ä½å‡½æ•°ï¼Œé¿å…åç»­è°ƒç”¨é”™è¯¯
    get_price = None
    get_realtime_quotes_sina = None
    get_stock_name = None


@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_ashare(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """
    ä½¿ç”¨Ashareè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '600519' æˆ– '000001'ï¼‰
        start: å¼€å§‹æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        end: ç»“æŸæ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        period_type: æ•°æ®å‘¨æœŸç±»å‹ï¼ˆ'daily'/'weekly'/'monthly'ï¼‰
    
    Returns:
        pd.DataFrame: åŒ…å«OHLCVæ•°æ®çš„DataFrameï¼Œç´¢å¼•ä¸ºæ—¥æœŸ
    
    Raises:
        Exception: æ•°æ®è·å–å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    
    Example:
        >>> df = get_stock_data_ashare('600519', '2023-01-01', '2023-12-31', 'daily')
        >>> print(df.head())
    """
    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        formatted_symbol = format_stock_code(symbol)

        # è½¬æ¢æ—¥æœŸæ ¼å¼
        # è½¬æ¢æ—¥æœŸæ ¼å¼ - Ashareåªæ”¯æŒend_dateå’Œcountå‚æ•°
        end_str = end.strftime("%Y-%m-%d") if hasattr(end, "strftime") else str(end)

        # è®¡ç®—éœ€è¦è·å–çš„æ•°æ®é‡
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)
        days_diff = (end_date - start_date).days

        # æ ¹æ®å‘¨æœŸç±»å‹è®¡ç®—count
        if period_type == "daily":
            count = min(
                max(days_diff + DATA_BUFFER_DAYS, MIN_DATA_COUNT_DAILY), MAX_DATA_COUNT_DAILY
            )
            frequency = "1d"
        elif period_type == "weekly":
            count = min(max(days_diff // 7 + 20, MIN_DATA_COUNT_WEEKLY), MAX_DATA_COUNT_WEEKLY)
            frequency = "1w"
        elif period_type == "monthly":
            count = min(max(days_diff // 30 + 12, MIN_DATA_COUNT_MONTHLY), MAX_DATA_COUNT_MONTHLY)
            frequency = "1M"
        else:
            st.error(f"ä¸æ”¯æŒçš„æ•°æ®å‘¨æœŸ: {period_type}")
            return pd.DataFrame()

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨Ashareè·å– {formatted_symbol} çš„æ•°æ®...")
        logger.debug(f"   ğŸ“… ç»“æŸæ—¥æœŸ: {end_str}")
        logger.debug(f"   ğŸ“Š æ•°æ®ç±»å‹: {period_type}")
        logger.debug(f"   ğŸ“ˆ è·å–æ•°é‡: {count} æ¡")

        # ä½¿ç”¨Ashareè·å–æ•°æ®
        df = get_price(formatted_symbol, end_date=end_str, count=count, frequency=frequency)

        if df.empty:
            logger.warning(f"âŒ Ashareè·å– {formatted_symbol} æ•°æ®ä¸ºç©º")
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å - å…ˆæ£€æŸ¥å®é™…åˆ—æ•°ï¼Œé¿å…åˆ—æ•°ä¸åŒ¹é…é”™è¯¯
        logger.debug(f"ğŸ“Š Ashareè¿”å›çš„åˆ—: {list(df.columns)}, åˆ—æ•°: {len(df.columns)}")
        
        # æ ¹æ®å®é™…åˆ—åæ˜ å°„åˆ°æ ‡å‡†åˆ—å
        column_mapping = {}
        # å¯èƒ½çš„åˆ—åå˜ä½“
        possible_names = {
            'open': 'Open',
            'Open': 'Open',
            'high': 'High',
            'High': 'High',
            'low': 'Low',
            'Low': 'Low',
            'close': 'Close',
            'Close': 'Close',
            'volume': 'Volume',
            'Volume': 'Volume',
        }
        
        # åªé€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        available_cols = []
        
        for col in df.columns:
            col_lower = col.lower()
            if col_lower in possible_names:
                target_col = possible_names[col_lower]
                if target_col not in column_mapping.values():
                    column_mapping[col] = target_col
                    available_cols.append(col)
        
        # å¦‚æœæ‰¾åˆ°äº†æ‰€æœ‰éœ€è¦çš„åˆ—ï¼Œé‡å‘½å
        if len(column_mapping) >= 5:
            df = df[available_cols].rename(columns=column_mapping)
        elif len(column_mapping) >= 4:
            # å¦‚æœç¼ºå°‘æŸäº›åˆ—ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å€¼
            logger.warning(f"âš ï¸ Ashareè¿”å›çš„åˆ—ä¸å®Œæ•´: {list(df.columns)}")
            df = df[available_cols].rename(columns=column_mapping)
            # è¡¥å……ç¼ºå¤±çš„åˆ—
            for req_col in required_cols:
                if req_col not in df.columns:
                    if req_col == 'Volume':
                        df[req_col] = 0
                    else:
                        df[req_col] = df.get('Close', 0)
        else:
            # å¦‚æœåˆ—åå®Œå…¨ä¸åŒ¹é…ï¼Œå°è¯•æŒ‰ä½ç½®æ˜ å°„ï¼ˆå‡è®¾é¡ºåºæ˜¯ open, high, low, close, volumeï¼‰
            logger.warning(f"âš ï¸ åˆ—åä¸åŒ¹é…ï¼Œå°è¯•æŒ‰ä½ç½®æ˜ å°„ã€‚å®é™…åˆ—: {list(df.columns)}")
            if len(df.columns) >= 5:
                # å‡è®¾å‰5åˆ—æ˜¯ OHLCV
                df = df.iloc[:, :5]
                df.columns = required_cols
            else:
                raise ValueError(f"Ashareè¿”å›çš„åˆ—æ•°ä¸è¶³: {len(df.columns)}åˆ—ï¼Œéœ€è¦5åˆ—")

        # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸæ—¶é—´ç±»å‹
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_index()

        # è¿‡æ»¤æ—¥æœŸèŒƒå›´
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)

        if end_date < df.index[0]:
            st.warning(f"è¯·æ±‚çš„ç»“æŸæ—¶é—´ {end_date.date()} æ—©äºæ•°æ®çš„æœ€æ—©æ—¶é—´ {df.index[0].date()}ï¼Œè¿”å›æœ€æ—©æ•°æ®")
            return df.head(min(MAX_RETURN_ROWS, len(df)))
        elif start_date > df.index[-1]:
            st.warning(f"è¯·æ±‚çš„å¼€å§‹æ—¶é—´ {start_date.date()} æ™šäºæ•°æ®çš„æœ€æ–°æ—¶é—´ {df.index[-1].date()}ï¼Œè¿”å›æœ€æ–°æ•°æ®")
            return df.tail(min(MAX_RETURN_ROWS, len(df)))
        else:
            mask = (df.index >= start_date) & (df.index <= end_date)
            df_filtered = df.loc[mask]

            if df_filtered.empty:
                return df.head(min(MAX_RETURN_ROWS, len(df)))

        logger.info(f"âœ… Ashareæ•°æ®è·å–æˆåŠŸ!")
        logger.debug(f"   ğŸ“Š æ•°æ®æ¡æ•°: {len(df_filtered)}")
        logger.debug(f"   ğŸ“… æ—¶é—´èŒƒå›´: {df_filtered.index[0]} åˆ° {df_filtered.index[-1]}")
        logger.debug(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {df_filtered['Close'].iloc[-1]:.2f}")

        return df_filtered

    except Exception as e:
        logger.error(f"Ashareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"Ashareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_ak(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä½¿ç”¨AKShareè·å–è‚¡ç¥¨æ•°æ®"""
    try:
        # æ¸…ç†è‚¡ç¥¨ä»£ç ï¼Œç§»é™¤å‰ç¼€å’Œåç¼€
        # AKShareéœ€è¦çº¯æ•°å­—ä»£ç ï¼Œå¦‚ "600519"
        formatted_symbol = symbol.strip()

        # ç§»é™¤ "sh" æˆ– "sz" å‰ç¼€
        if formatted_symbol.lower().startswith(("sh", "sz")):
            formatted_symbol = formatted_symbol[2:]

        # ç§»é™¤ ".SH" æˆ– ".SZ" åç¼€
        if "." in formatted_symbol:
            formatted_symbol = formatted_symbol.split(".")[0]

        # ç¡®ä¿æ˜¯çº¯æ•°å­—
        formatted_symbol = "".join(filter(str.isdigit, formatted_symbol))

        if not formatted_symbol:
            st.error("âŒ æ— æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return pd.DataFrame()

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨AKShareè·å– {formatted_symbol} çš„æ•°æ®...")

        # æ ¹æ®å‘¨æœŸç±»å‹è·å–æ•°æ®
        if period_type in ["daily", "weekly", "monthly"]:
            # è½¬æ¢å‘¨æœŸå‚æ•°
            period_map = {"daily": "daily", "weekly": "weekly", "monthly": "monthly"}
            period = period_map[period_type]

            # æ ¼å¼åŒ–æ—¥æœŸ
            start_date = (
                start.strftime("%Y%m%d")
                if hasattr(start, "strftime")
                else str(start).replace("-", "")
            )
            end_date = (
                end.strftime("%Y%m%d") if hasattr(end, "strftime") else str(end).replace("-", "")
            )

            # è·å–è‚¡ç¥¨å†å²æ•°æ®
            df = ak.stock_zh_a_hist(
                symbol=formatted_symbol,
                period=period,
                start_date=start_date,
                end_date=end_date,
                adjust="qfq",
            )

            if df.empty:
                return pd.DataFrame()

            # å¤„ç†æ—¥æœŸå’Œç´¢å¼•
            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
            df = df.sort_values("æ—¥æœŸ").set_index("æ—¥æœŸ")

            # æ ‡å‡†åŒ–åˆ—å
            if "å¼€ç›˜" in df.columns:
                df = df.rename(
                    columns={
                        "å¼€ç›˜": "Open",
                        "æ”¶ç›˜": "Close",
                        "æœ€é«˜": "High",
                        "æœ€ä½": "Low",
                        "æˆäº¤é‡": "Volume",
                    }
                )

            logger.info(f"âœ… AKShareæ•°æ®è·å–æˆåŠŸ!")
            logger.debug(f"   ğŸ“Š æ•°æ®æ¡æ•°: {len(df)}")
            if not df.empty:
                logger.debug(f"   ğŸ“… æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
                logger.debug(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {df['Close'].iloc[-1]:.2f}")

            return df

    except Exception as e:
        logger.error(f"AKShareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"AKShareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


# å°è¯•å¯¼å…¥Tushareç›¸å…³æ¨¡å—
try:
    import os
    import sys

    # æ·»åŠ aitrader_coreåˆ°è·¯å¾„
    sys.path.append(os.path.join(os.path.dirname(__file__), "..", "aitrader_core"))
    from datafeed.tushare_loader import get_stock_data as tushare_get_stock_data

    has_tushare = True
except ImportError:
    has_tushare = False
    logger.warning("âš ï¸ Tushareæ¨¡å—æœªæ‰¾åˆ°")

# å°è¯•å¯¼å…¥CSVæ•°æ®åŠ è½½å™¨
try:
    from datafeed.csv_dataloader import CsvDataLoader

    has_csv = True
except ImportError:
    has_csv = False
    logger.warning("âš ï¸ CSVæ•°æ®åŠ è½½å™¨æœªæ‰¾åˆ°")


@st.cache_data(ttl=CACHE_TTL_ONLINE_DATA, show_spinner=False)
def get_stock_data_tushare(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä½¿ç”¨Tushareè·å–è‚¡ç¥¨æ•°æ®"""
    if not has_tushare:
        st.warning("Tushareæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥aitrader_core/datafeed/tushare_loader.py")
        return pd.DataFrame()

    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä¸ºTushareæ ¼å¼ (å¦‚: 600519.SH)
        if "." not in symbol:
            if symbol.startswith("6"):
                symbol = f"{symbol}.SH"
            elif symbol.startswith(("0", "3")):
                symbol = f"{symbol}.SZ"

        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨Tushareè·å– {symbol} çš„æ•°æ®...")

        # è°ƒç”¨tushare_loader (æ³¨æ„ï¼štushare_loaderæ²¡æœ‰freqå‚æ•°ï¼Œåªæ”¯æŒæ—¥çº¿)
        df = tushare_get_stock_data(
            symbol=symbol,
            start_date=start.strftime("%Y%m%d")
            if hasattr(start, "strftime")
            else str(start).replace("-", ""),
            end_date=end.strftime("%Y%m%d")
            if hasattr(end, "strftime")
            else str(end).replace("-", ""),
        )

        if df is None or df.empty:
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å (tushareè¿”å›å°å†™åˆ—å)
        column_mapping = {
            "date": "Date",
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
        }

        df = df.rename(columns=column_mapping)

        # ç¡®ä¿Dateåˆ—æ˜¯datetimeç±»å‹
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date")

        # åªä¿ç•™éœ€è¦çš„åˆ—
        required_columns = ["Open", "High", "Low", "Close", "Volume"]
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_index()

        logger.info(f"âœ… Tushareæ•°æ®è·å–æˆåŠŸ! æ•°æ®æ¡æ•°: {len(df)}")
        return df

    except Exception as e:
        logger.error(f"Tushareæ•°æ®è·å–å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"Tushareæ•°æ®è·å–å¤±è´¥: {str(e)}")
        return pd.DataFrame()


@st.cache_data(ttl=CACHE_TTL_LOCAL_DATA, show_spinner=False)
def get_stock_data_csv(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
) -> pd.DataFrame:
    """ä»æœ¬åœ°CSVæ–‡ä»¶è·å–è‚¡ç¥¨æ•°æ®"""
    if not has_csv:
        st.warning("CSVæ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")
        return pd.DataFrame()

    try:
        # æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        if "." not in symbol:
            if symbol.startswith("6"):
                symbol = f"{symbol}.SH"
            elif symbol.startswith(("0", "3")):
                symbol = f"{symbol}.SZ"

        logger.info(f"ğŸ”„ æ­£åœ¨ä»æœ¬åœ°CSVè·å– {symbol} çš„æ•°æ®...")

        # é¦–å…ˆå°è¯•ç”¨æˆ·ç›®å½•ä¸‹çš„stock_dataæ–‡ä»¶å¤¹
        user_stock_data_dir = os.path.expanduser("~/stock_data")

        # åˆ›å»ºCSVåŠ è½½å™¨å®ä¾‹ (CsvDataLoaderä¸æ¥å—data_dirå‚æ•°)
        csv_loader = CsvDataLoader()

        # æ ¹æ®è·¯å¾„å†³å®šä½¿ç”¨å“ªä¸ªç›®å½•
        if os.path.exists(user_stock_data_dir):
            csv_path = user_stock_data_dir
            logger.debug(f"ğŸ“ ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {user_stock_data_dir}")
        else:
            # å›é€€åˆ°é»˜è®¤è·¯å¾„ (ä½¿ç”¨'quotes'ä¼šè‡ªåŠ¨ä½¿ç”¨DATA_DIR/quotes)
            csv_path = "quotes"
            logger.debug(f"ğŸ“ ä½¿ç”¨é»˜è®¤æ•°æ®ç›®å½•")

        # è¯»å–CSVæ•°æ® (ä¼ å…¥pathå‚æ•°)
        df = csv_loader._read_csv(symbol, path=csv_path)

        if df is None or df.empty:
            st.warning(f"æœ¬åœ°CSVæœªæ‰¾åˆ° {symbol} çš„æ•°æ®æ–‡ä»¶")
            st.info("ğŸ’¡ è¯·å…ˆåœ¨ã€ŒAIæ•°æ®ç®¡ç†ã€ä¸­æ›´æ–°è‚¡ç¥¨æ•°æ®")
            return pd.DataFrame()

        # æ ‡å‡†åŒ–åˆ—å (CSVé€šå¸¸è¿”å›å°å†™åˆ—å)
        column_mapping = {
            "date": "Date",
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
        }

        df = df.rename(columns=column_mapping)

        # ç¡®ä¿Dateåˆ—æ˜¯datetimeç±»å‹å¹¶è®¾ç½®ä¸ºç´¢å¼•
        if "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date")

        # åªä¿ç•™éœ€è¦çš„åˆ—
        required_columns = ["Open", "High", "Low", "Close", "Volume"]
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]

        # æŒ‰æ—¥æœŸè¿‡æ»¤
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)
        df = df[(df.index >= start_date) & (df.index <= end_date)]

        if df.empty:
            st.warning(f"âš ï¸ åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…({start} è‡³ {end})æœªæ‰¾åˆ°æ•°æ®")
            return pd.DataFrame()

        logger.info(f"âœ… CSVæ•°æ®åŠ è½½æˆåŠŸ! æ•°æ®æ¡æ•°: {len(df)}")
        return df

    except Exception as e:
        logger.error(f"CSVæ•°æ®åŠ è½½å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"CSVæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return pd.DataFrame()


def get_stock_data(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
    data_source: str = "Ashare",
) -> pd.DataFrame:
    """
    è·å–è‚¡ç¥¨æ•°æ®çš„ä¸»å‡½æ•°ï¼Œæ ¹æ®æ•°æ®æºé€‰æ‹©ä¸åŒçš„è·å–æ–¹æ³•
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '600519' æˆ– '000001'ï¼‰
        start: å¼€å§‹æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        end: ç»“æŸæ—¥æœŸï¼ˆå­—ç¬¦ä¸²ã€datetimeæˆ–Timestampï¼‰
        period_type: æ•°æ®å‘¨æœŸç±»å‹ï¼ˆ'daily'/'weekly'/'monthly'ï¼‰
        data_source: æ•°æ®æºé€‰æ‹©ï¼ˆ'Ashare'/'AKShare'/'Tushare'/'æœ¬åœ°CSV'ï¼‰
    
    Returns:
        pd.DataFrame: åŒ…å«OHLCVæ•°æ®çš„DataFrameï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œå·²è¿‡æ»¤éäº¤æ˜“æ—¥
    
    Note:
        - è‡ªåŠ¨åº”ç”¨äº¤æ˜“æ—¥è¿‡æ»¤ï¼ˆæ’é™¤å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
        - æ”¯æŒå¤šç§æ•°æ®æºè‡ªåŠ¨å›é€€
        - æ•°æ®è‡ªåŠ¨ç¼“å­˜ï¼ˆåœ¨çº¿æ•°æ®1å°æ—¶ï¼Œæœ¬åœ°æ•°æ®2å°æ—¶ï¼‰
    
    Example:
        >>> df = get_stock_data('600519', '2023-01-01', '2023-12-31', 'daily', 'Ashare')
        >>> print(f"è·å–åˆ° {len(df)} æ¡äº¤æ˜“æ—¥æ•°æ®")
    """
    try:
        # ========== æ•°æ®éªŒè¯ ==========
        # éªŒè¯è‚¡ç¥¨ä»£ç 
        is_valid_code, code_error = validate_stock_code(symbol)
        if not is_valid_code:
            st.error(f"âŒ {code_error}")
            st.info("ğŸ’¡ **æç¤ºï¼š** è¯·è¾“å…¥6ä½æ•°å­—çš„Aè‚¡ä»£ç ï¼Œå¦‚ï¼š600519ï¼ˆè´µå·èŒ…å°ï¼‰ã€000001ï¼ˆå¹³å®‰é“¶è¡Œï¼‰")
            return pd.DataFrame()
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        if not isinstance(start, (str, pd.Timestamp, datetime.datetime)):
            start = pd.to_datetime(start, format="%Y%m%d")
        if not isinstance(end, (str, pd.Timestamp, datetime.datetime)):
            end = pd.to_datetime(end, format="%Y%m%d")
        
        # éªŒè¯æ—¥æœŸèŒƒå›´
        is_valid_date, date_error = validate_date_range(start, end)
        if not is_valid_date:
            st.error(f"âŒ {date_error}")
            return pd.DataFrame()

        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ•°æ®æºè·å–æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        df = _get_stock_data_with_retry(symbol, start, end, period_type, data_source)

        # ğŸ”§ ç»Ÿä¸€åº”ç”¨äº¤æ˜“æ—¥è¿‡æ»¤ï¼Œç¡®ä¿Kçº¿è¿ç»­æ˜¾ç¤º
        if not df.empty and period_type in ["daily", "weekly", "monthly"]:
            from .trading_calendar import filter_trading_days

            original_count = len(df)
            df = filter_trading_days(df)
            filtered_count = len(df)

            if filtered_count < original_count:
                st.info(f"ğŸ“… äº¤æ˜“æ—¥è¿‡æ»¤: {original_count} â†’ {filtered_count} æ¡æ•°æ®")
                st.success(f"âœ… å·²è¿‡æ»¤æ‰ {original_count - filtered_count} ä¸ªéäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        if not df.empty:
            quality_info = check_data_quality(df, symbol)
            if quality_info.get('warnings'):
                for warning in quality_info['warnings']:
                    st.warning(f"âš ï¸ {warning}")

        return df

    except Exception as e:
        # æ ¼å¼åŒ–ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        error_message = format_user_friendly_error(e, symbol, data_source)
        st.error(error_message)
        
        # è®°å½•è¯¦ç»†é”™è¯¯æ—¥å¿—
        logger.error(
            f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: symbol={symbol}, data_source={data_source}, "
            f"start={start}, end={end}, period_type={period_type}, "
            f"error={type(e).__name__}: {str(e)}",
            exc_info=True
        )
        
        return pd.DataFrame()


# å…¶ä»–è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜
def get_realtime_price(symbol: str) -> Optional[float]:
    """è·å–å®æ—¶è‚¡ä»·"""
    try:
        # ä½¿ç”¨ç¼“å­˜çš„å®æ—¶æ•°æ®
        return cached_realtime_data(symbol)
    except Exception as e:
        st.error(f"è·å–å®æ—¶ä»·æ ¼å¤±è´¥: {str(e)}")
        return None


def get_stock_info(symbol: str) -> Optional[pd.DataFrame]:
    """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    try:
        formatted_symbol = format_stock_code(symbol)

        if has_ashare:
            # ä½¿ç”¨Ashareè·å–è‚¡ç¥¨ä¿¡æ¯
            try:
                from .Ashare import get_security_info

                info = get_security_info(formatted_symbol)
                return info
            except (ImportError, AttributeError):
                logger.warning("Ashareçš„get_security_infoå‡½æ•°ä¸å¯ç”¨")
                # å›é€€åˆ°AKShare
                info = ak.stock_individual_info_em(symbol=formatted_symbol)
                return info
        else:
            # ä½¿ç”¨AKShareè·å–è‚¡ç¥¨ä¿¡æ¯
            info = ak.stock_individual_info_em(symbol=formatted_symbol)
            return info

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
        st.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None


# ========== å¼‚æ­¥æ‰¹é‡æ•°æ®è·å–ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰ ==========


def _fetch_single_stock_sync(
    symbol: str,
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str,
    data_source: str,
) -> Dict[str, Any]:
    """
    åŒæ­¥è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆç”¨äºå¼‚æ­¥å¹¶å‘ï¼‰

    Returns:
        dict: {'symbol': str, 'status': 'success'|'error', 'data': pd.DataFrame|None, 'error': str|None}
    """
    try:
        df = get_stock_data(symbol, start, end, period_type, data_source)
        if df is not None and not df.empty:
            return {"symbol": symbol, "status": "success", "data": df, "error": None}
        else:
            return {"symbol": symbol, "status": "error", "data": None, "error": "æ•°æ®ä¸ºç©º"}
    except Exception as e:
        logger.error(f"è·å– {symbol} æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
        return {"symbol": symbol, "status": "error", "data": None, "error": str(e)}


async def get_multiple_stocks_data_async(
    symbols: List[str],
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str = "daily",
    data_source: str = "Ashare",
    max_workers: int = ASYNC_BATCH_FETCH_WORKERS,
    progress_callback: Optional[Callable] = None,
) -> Dict[str, pd.DataFrame]:
    """
    å¼‚æ­¥æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        period_type: æ•°æ®å‘¨æœŸç±»å‹
        data_source: æ•°æ®æº
        max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼Œé¿å…APIé™æµï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total, symbol)

    Returns:
        dict: {symbol: DataFrame} æˆåŠŸè·å–çš„æ•°æ®å­—å…¸

    Example:
        symbols = ['600519', '000001', '000002']
        data_dict = await get_multiple_stocks_data_async(
            symbols, '2023-01-01', '2023-12-31'
        )
        # è¿”å›: {'600519': DataFrame, '000001': DataFrame, ...}
    """
    logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ‰¹é‡è·å– {len(symbols)} åªè‚¡ç¥¨æ•°æ®ï¼ˆå¹¶å‘æ•°: {max_workers}ï¼‰")

    loop = asyncio.get_event_loop()
    results = {}
    completed = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:

        async def fetch_single(symbol: str):
            return await loop.run_in_executor(
                executor, _fetch_single_stock_sync, symbol, start, end, period_type, data_source
            )

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        tasks = [fetch_single(symbol) for symbol in symbols]
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(task_results):
            symbol = symbols[i]
            completed += 1

            if isinstance(result, Exception):
                logger.error(f"è·å– {symbol} æ•°æ®å¼‚å¸¸: {result}", exc_info=True)
                if progress_callback:
                    progress_callback(completed, len(symbols), symbol)
                continue

            if isinstance(result, dict):
                if result["status"] == "success" and result["data"] is not None:
                    results[symbol] = result["data"]
                    logger.debug(f"âœ… {symbol} æ•°æ®è·å–æˆåŠŸ: {len(result['data'])} æ¡")
                else:
                    logger.warning(f"âš ï¸ {symbol} æ•°æ®è·å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

                if progress_callback:
                    progress_callback(completed, len(symbols), symbol)

    logger.info(f"âœ… å¼‚æ­¥æ‰¹é‡è·å–å®Œæˆ: æˆåŠŸ {len(results)}/{len(symbols)} åª")
    return results


def get_multiple_stocks_data(
    symbols: List[str],
    start: Union[str, datetime.datetime, pd.Timestamp],
    end: Union[str, datetime.datetime, pd.Timestamp],
    period_type: str = "daily",
    data_source: str = "Ashare",
    use_async: bool = True,
    max_workers: int = 5,
) -> Dict[str, pd.DataFrame]:
    """
    æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®ï¼ˆåŒæ­¥æ¥å£ï¼Œå†…éƒ¨å¯é€‰æ‹©å¼‚æ­¥ï¼‰

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start: å¼€å§‹æ—¥æœŸ
        end: ç»“æŸæ—¥æœŸ
        period_type: æ•°æ®å‘¨æœŸç±»å‹
        data_source: æ•°æ®æº
        use_async: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼Œæ€§èƒ½æå‡3-5å€ï¼‰
        max_workers: å¼‚æ­¥æ¨¡å¼çš„æœ€å¤§å¹¶å‘æ•°

    Returns:
        dict: {symbol: DataFrame} æˆåŠŸè·å–çš„æ•°æ®å­—å…¸
    """
    if use_async:
        # å¼‚æ­¥æ¨¡å¼
        try:
            return asyncio.run(
                get_multiple_stocks_data_async(
                    symbols, start, end, period_type, data_source, max_workers
                )
            )
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ‰¹é‡è·å–å¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼: {e}")
            # å›é€€åˆ°åŒæ­¥æ¨¡å¼
            use_async = False

    if not use_async:
        # åŒæ­¥æ¨¡å¼
        results = {}
        for i, symbol in enumerate(symbols):
            try:
                df = get_stock_data(symbol, start, end, period_type, data_source)
                if df is not None and not df.empty:
                    results[symbol] = df
                    logger.debug(f"âœ… {symbol} æ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡")
            except Exception as e:
                logger.warning(f"âš ï¸ {symbol} æ•°æ®è·å–å¤±è´¥: {str(e)}")

        return results
