"""
Zå“¥æˆ˜æ³•æ•°æ®ç®¡ç†æ¨¡å—
è´Ÿè´£æœ¬åœ°CSVæ•°æ®çš„ä¸‹è½½ã€å­˜å‚¨å’ŒåŠ è½½
"""
import os
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import time

# æ•°æ®å­˜å‚¨ç›®å½•
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'zgzf_data')

def ensure_data_dir():
    """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
        print(f"âœ… åˆ›å»ºæ•°æ®ç›®å½•: {DATA_DIR}")
    return DATA_DIR

def get_stock_list_from_index(index_code: str) -> Optional[List[str]]:
    """
    ä»æŒ‡æ•°è·å–æˆåˆ†è‚¡åˆ—è¡¨
    
    Args:
        index_code: æŒ‡æ•°ä»£ç  (000300=æ²ªæ·±300, 000905=ä¸­è¯500, 000016=ä¸Šè¯50)
    
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    try:
        import akshare as ak
        
        index_map = {
            "000300": "æ²ªæ·±300",
            "000905": "ä¸­è¯500",
            "000016": "ä¸Šè¯50"
        }
        
        print(f"ğŸ“Š æ­£åœ¨è·å–{index_map.get(index_code, index_code)}æˆåˆ†è‚¡...")
        df = ak.index_stock_cons_csindex(symbol=index_code)
        
        if df is not None and not df.empty:
            stock_list = df['æˆåˆ†åˆ¸ä»£ç '].tolist()
            print(f"âœ… è·å–åˆ° {len(stock_list)} åªæˆåˆ†è‚¡")
            return stock_list
        else:
            print("âŒ è·å–æˆåˆ†è‚¡å¤±è´¥")
            return None
    except Exception as e:
        print(f"âŒ è·å–æˆåˆ†è‚¡å‡ºé”™: {e}")
        return None

def download_stock_data_to_csv(
    stock_code: str,
    start_date: str,
    end_date: str,
    data_source: str = "AKShare"
) -> bool:
    """
    ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®å¹¶ä¿å­˜ä¸ºCSV
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        data_source: æ•°æ®æº
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        from .data_loader import get_stock_data
        
        df = get_stock_data(
            symbol=stock_code,
            start=start_date,
            end=end_date,
            data_source=data_source,
            period_type='daily'
        )
        
        if df is None or df.empty:
            return False
        
        # ä¿å­˜åˆ°CSV
        ensure_data_dir()
        csv_path = os.path.join(DATA_DIR, f"{stock_code}.csv")
        
        # ä¿å­˜æ—¶åŒ…å«æ—¥æœŸç´¢å¼•
        df.to_csv(csv_path, encoding='utf-8-sig')
        
        return True
    except Exception as e:
        print(f"âŒ {stock_code} ä¸‹è½½å¤±è´¥: {e}")
        return False

def batch_download_stocks(
    stock_list: List[str],
    start_date: str,
    end_date: str,
    data_source: str = "AKShare",
    progress_callback=None
) -> Dict[str, str]:
    """
    æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        data_source: æ•°æ®æº
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, code)
    
    Returns:
        {'success': [...], 'failed': [...]}
    """
    success_list = []
    failed_list = []
    
    total = len(stock_list)
    
    for idx, code in enumerate(stock_list):
        if progress_callback:
            progress_callback(idx + 1, total, code)
        
        if download_stock_data_to_csv(code, start_date, end_date, data_source):
            success_list.append(code)
        else:
            failed_list.append(code)
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.1)
    
    return {
        'success': success_list,
        'failed': failed_list
    }

def load_stock_data_from_csv(stock_code: str) -> Optional[pd.DataFrame]:
    """
    ä»CSVåŠ è½½è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
    
    Returns:
        DataFrameæˆ–None
    """
    try:
        csv_path = os.path.join(DATA_DIR, f"{stock_code}.csv")
        
        if not os.path.exists(csv_path):
            return None
        
        # è¯»å–CSVï¼Œç¬¬ä¸€åˆ—ä½œä¸ºç´¢å¼•ï¼ˆæ—¥æœŸï¼‰
        df = pd.read_csv(csv_path, index_col=0, parse_dates=True)
        
        return df
    except Exception as e:
        print(f"âŒ {stock_code} åŠ è½½å¤±è´¥: {e}")
        return None

def get_local_stock_list() -> List[str]:
    """
    è·å–æœ¬åœ°å·²ä¸‹è½½çš„è‚¡ç¥¨åˆ—è¡¨
    
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    ensure_data_dir()
    
    stock_list = []
    
    for filename in os.listdir(DATA_DIR):
        if filename.endswith('.csv'):
            stock_code = filename.replace('.csv', '')
            stock_list.append(stock_code)
    
    return sorted(stock_list)

def load_all_local_stocks() -> Dict[str, pd.DataFrame]:
    """
    åŠ è½½æ‰€æœ‰æœ¬åœ°è‚¡ç¥¨æ•°æ®
    
    Returns:
        {è‚¡ç¥¨ä»£ç : DataFrame} å­—å…¸
    """
    stock_list = get_local_stock_list()
    stock_data_dict = {}
    
    for code in stock_list:
        df = load_stock_data_from_csv(code)
        if df is not None and not df.empty and len(df) >= 60:
            stock_data_dict[code] = df
    
    return stock_data_dict

def get_data_info() -> Dict:
    """
    è·å–æœ¬åœ°æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        {'count': int, 'oldest': str, 'newest': str, 'total_size': str}
    """
    stock_list = get_local_stock_list()
    
    if not stock_list:
        return {
            'count': 0,
            'oldest': 'N/A',
            'newest': 'N/A',
            'total_size': '0 MB'
        }
    
    # è®¡ç®—æ€»å¤§å°
    total_size = 0
    oldest_date = None
    newest_date = None
    
    for code in stock_list:
        csv_path = os.path.join(DATA_DIR, f"{code}.csv")
        if os.path.exists(csv_path):
            total_size += os.path.getsize(csv_path)
            
            # è·å–æ—¥æœŸèŒƒå›´
            try:
                df = pd.read_csv(csv_path, index_col=0, parse_dates=True)
                if not df.empty:
                    file_oldest = df.index.min()
                    file_newest = df.index.max()
                    
                    if oldest_date is None or file_oldest < oldest_date:
                        oldest_date = file_oldest
                    if newest_date is None or file_newest > newest_date:
                        newest_date = file_newest
            except:
                continue
    
    return {
        'count': len(stock_list),
        'oldest': oldest_date.strftime('%Y-%m-%d') if oldest_date else 'N/A',
        'newest': newest_date.strftime('%Y-%m-%d') if newest_date else 'N/A',
        'total_size': f"{total_size / 1024 / 1024:.2f} MB"
    }

def clear_all_data():
    """æ¸…ç©ºæ‰€æœ‰æœ¬åœ°æ•°æ®"""
    stock_list = get_local_stock_list()
    
    for code in stock_list:
        csv_path = os.path.join(DATA_DIR, f"{code}.csv")
        try:
            os.remove(csv_path)
        except:
            pass
    
    print(f"âœ… å·²æ¸…ç©º {len(stock_list)} ä¸ªæ•°æ®æ–‡ä»¶")


def display_data_management():
    """æ˜¾ç¤ºæ•°æ®ç®¡ç†ç•Œé¢"""
    st.title("ğŸ“¦ Zå“¥æˆ˜æ³• - æ•°æ®ç®¡ç†")
    
    st.markdown("""
    ### æ•°æ®ç®¡ç†è¯´æ˜
    
    æ‰¹é‡é€‰è‚¡éœ€è¦æå‰ä¸‹è½½è‚¡ç¥¨æ•°æ®åˆ°æœ¬åœ°ã€‚æœ¬åœ°æ•°æ®çš„ä¼˜åŠ¿ï¼š
    - âš¡ **é€Ÿåº¦å¿«**ï¼šæ— éœ€å®æ—¶è¯·æ±‚API
    - ğŸ’° **çœæˆæœ¬**ï¼šå‡å°‘APIè°ƒç”¨æ¬¡æ•°
    - ğŸ”’ **ç¨³å®šæ€§**ï¼šä¸å—ç½‘ç»œæ³¢åŠ¨å½±å“
    
    **ä½¿ç”¨æµç¨‹**ï¼š
    1. é€‰æ‹©è‚¡ç¥¨æ± ï¼ˆæ²ªæ·±300/ä¸­è¯500/ä¸Šè¯50ï¼‰
    2. ç‚¹å‡»"ä¸‹è½½æ•°æ®"æ‰¹é‡ä¸‹è½½
    3. è¿”å›"Zå“¥æˆ˜æ³•é€‰è‚¡"è¿›è¡Œæ‰¹é‡ç­›é€‰
    """)
    
    st.markdown("---")
    
    # å½“å‰æ•°æ®ç»Ÿè®¡
    st.subheader("ğŸ“Š æœ¬åœ°æ•°æ®ç»Ÿè®¡")
    
    info = get_data_info()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("è‚¡ç¥¨æ•°é‡", info['count'])
    
    with col2:
        st.metric("æœ€æ—©æ—¥æœŸ", info['oldest'])
    
    with col3:
        st.metric("æœ€æ–°æ—¥æœŸ", info['newest'])
    
    with col4:
        st.metric("å ç”¨ç©ºé—´", info['total_size'])
    
    if info['count'] > 0:
        with st.expander("ğŸ“‹ æŸ¥çœ‹å·²ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨"):
            stock_list = get_local_stock_list()
            # æ¯è¡Œæ˜¾ç¤º10ä¸ª
            cols_per_row = 10
            for i in range(0, len(stock_list), cols_per_row):
                row_stocks = stock_list[i:i+cols_per_row]
                st.text(", ".join(row_stocks))
    
    st.markdown("---")
    
    # æ•°æ®ä¸‹è½½
    st.subheader("ğŸ“¥ æ‰¹é‡ä¸‹è½½æ•°æ®")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        stock_pool = st.selectbox(
            "é€‰æ‹©è‚¡ç¥¨æ± ",
            ["æ²ªæ·±300", "ä¸­è¯500", "ä¸Šè¯50", "è‡ªå®šä¹‰åˆ—è¡¨"]
        )
    
    with col2:
        data_source = st.selectbox("æ•°æ®æº", ["AKShare", "Tushare"])
    
    with col3:
        days = st.number_input("å†å²å¤©æ•°", min_value=30, max_value=1000, value=365, step=30)
    
    # è‡ªå®šä¹‰åˆ—è¡¨
    if stock_pool == "è‡ªå®šä¹‰åˆ—è¡¨":
        custom_list = st.text_area(
            "è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆæ¯è¡Œä¸€ä¸ªæˆ–é€—å·åˆ†éš”ï¼‰",
            value="600519\n000858\n601318",
            height=100
        )
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸš€ å¼€å§‹ä¸‹è½½", type="primary", use_container_width=True):
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = []
            
            if stock_pool == "è‡ªå®šä¹‰åˆ—è¡¨":
                raw_input = custom_list.replace(',', '\n')
                stock_list = [s.strip() for s in raw_input.split('\n') if s.strip()]
            else:
                # è·å–æŒ‡æ•°æˆåˆ†è‚¡
                index_map = {
                    "æ²ªæ·±300": "000300",
                    "ä¸­è¯500": "000905",
                    "ä¸Šè¯50": "000016"
                }
                
                with st.spinner(f"æ­£åœ¨è·å–{stock_pool}æˆåˆ†è‚¡..."):
                    stock_list = get_stock_list_from_index(index_map[stock_pool])
                
                if not stock_list:
                    st.error("è·å–æˆåˆ†è‚¡å¤±è´¥")
                    st.stop()
            
            if not stock_list:
                st.warning("è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
                st.stop()
            
            st.info(f"ğŸ“Š å‡†å¤‡ä¸‹è½½ {len(stock_list)} åªè‚¡ç¥¨çš„æ•°æ®...")
            
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            # è¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, code):
                progress_bar.progress(current / total)
                status_text.text(f"æ­£åœ¨ä¸‹è½½: {code} ({current}/{total})")
            
            # æ‰¹é‡ä¸‹è½½
            result = batch_download_stocks(
                stock_list,
                start_date.strftime("%Y-%m-%d"),
                end_date.strftime("%Y-%m-%d"),
                data_source,
                progress_callback
            )
            
            progress_bar.empty()
            status_text.empty()
            
            # æ˜¾ç¤ºç»“æœ
            st.success(f"âœ… æˆåŠŸä¸‹è½½ {len(result['success'])} åªè‚¡ç¥¨")
            
            if result['failed']:
                with st.expander(f"âš ï¸ {len(result['failed'])} åªè‚¡ç¥¨ä¸‹è½½å¤±è´¥"):
                    st.write(", ".join(result['failed']))
            
            # åˆ·æ–°ç»Ÿè®¡ä¿¡æ¯
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ•°æ®", use_container_width=True):
            if info['count'] > 0:
                with st.spinner("æ­£åœ¨æ¸…ç©ºæ•°æ®..."):
                    clear_all_data()
                st.success("âœ… æ•°æ®å·²æ¸…ç©º")
                st.rerun()
            else:
                st.info("æš‚æ— æ•°æ®éœ€è¦æ¸…ç©º")
    
    st.markdown("---")
    
    # ä½¿ç”¨æç¤º
    st.info("""
    ğŸ’¡ **ä¸‹ä¸€æ­¥**ï¼š
    1. ä¸‹è½½å®Œæˆåï¼Œè¿”å›"Zå“¥æˆ˜æ³•é€‰è‚¡"æ¨¡å—
    2. é€‰æ‹©"æ‰¹é‡é€‰è‚¡"æ¨¡å¼
    3. é€‰æ‹©"ä»æœ¬åœ°æ•°æ®"
    4. å¼€å§‹ç­›é€‰ï¼
    """)


if __name__ == "__main__":
    display_data_management()

